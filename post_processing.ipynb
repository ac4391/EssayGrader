{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from src.preprocess import confusion_matrix, histogram, quadratic_weighted_kappa, pearson_correlation, Mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Essay=pd.read_pickle('./data/essay_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are evaluated upon Pearsonâ€™s correlation, mean absolute error, and quadratic weighted\n",
    "kappa. We evaluate those metric for each set to estimate if our normalization and training on the whole sets included a bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Essay['prediction']=df_Essay['rater1_domain1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>max_score</th>\n",
       "      <th>norm_score1</th>\n",
       "      <th>norm_score2</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[[-0.45701, 0.23121, 0.87486, -0.7933, -0.1945...</td>\n",
       "      <td>299</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[[-0.45701, 0.23121, 0.87486, -0.7933, -0.1945...</td>\n",
       "      <td>349</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[[-0.45701, 0.23121, 0.87486, -0.7933, -0.1945...</td>\n",
       "      <td>236</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[[-0.45701, 0.23121, 0.87486, -0.7933, -0.1945...</td>\n",
       "      <td>449</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[[-0.45701, 0.23121, 0.87486, -0.7933, -0.1945...</td>\n",
       "      <td>387</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  \\\n",
       "0               4               4   \n",
       "1               5               4   \n",
       "2               4               3   \n",
       "3               5               5   \n",
       "4               4               4   \n",
       "\n",
       "                                        essays_embed  word_count  max_score  \\\n",
       "0  [[-0.45701, 0.23121, 0.87486, -0.7933, -0.1945...         299       12.0   \n",
       "1  [[-0.45701, 0.23121, 0.87486, -0.7933, -0.1945...         349       12.0   \n",
       "2  [[-0.45701, 0.23121, 0.87486, -0.7933, -0.1945...         236       12.0   \n",
       "3  [[-0.45701, 0.23121, 0.87486, -0.7933, -0.1945...         449       12.0   \n",
       "4  [[-0.45701, 0.23121, 0.87486, -0.7933, -0.1945...         387       12.0   \n",
       "\n",
       "   norm_score1  norm_score2  prediction  \n",
       "0            4            4           4  \n",
       "1            5            4           5  \n",
       "2            4            3           4  \n",
       "3            5            5           5  \n",
       "4            4            4           4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Essay.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With library sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7172861726670788,\n",
       " 0.7708155194901584,\n",
       " 0.8509405766098401,\n",
       " 0.7527010280573945,\n",
       " 0.7765388466877478]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pearson's correlation\n",
    "pearson_corr = []\n",
    "for i in [1,3,4,5,6]:\n",
    "    pearson_corr+=[stats.pearsonr(df_Essay[df_Essay['essay_set']==i]['rater1_domain1'], df_Essay[df_Essay['essay_set']==i]['rater2_domain1'])[0]]\n",
    "pearson_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35895986433013,\n",
       " 0.2566628041714948,\n",
       " 0.2288135593220339,\n",
       " 0.44155124653739614,\n",
       " 0.3933333333333333]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean absolute error\n",
    "MAE=[]\n",
    "for i in [1,3,4,5,6]:\n",
    "    MAE+=[metrics.mean_absolute_error(df_Essay[df_Essay['essay_set']==i]['rater1_domain1'], df_Essay[df_Essay['essay_set']==i]['rater2_domain1'])]\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7169197767600322,\n",
       " 0.769230064491969,\n",
       " 0.8509277825717176,\n",
       " 0.7526961695797694,\n",
       " 0.7764876632801161]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quadratic weighted kappa\n",
    "Kappa=[]\n",
    "for i in [1,3,4,5,6]:\n",
    "    Kappa+=[metrics.cohen_kappa_score(df_Essay[df_Essay['essay_set']==i]['rater1_domain1'], df_Essay[df_Essay['essay_set']==i]['rater2_domain1'], weights = 'quadratic')]\n",
    "Kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If we can't use sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kappa functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 17, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 7, 110, 77, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 58, 685, 168, 11, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 166, 292, 43, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 9, 61, 42, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_Essay[df_Essay['essay_set']==1]['norm_score1'], df_Essay[df_Essay['essay_set']==1]['norm_score2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 10, 28, 196, 922, 501, 112, 0, 0, 0, 0, 0, 0], [0, 11, 24, 178, 937, 523, 96, 0, 0, 0, 0, 0, 0]]\n",
      "[[41, 0, 0, 0, 680, 0, 0, 0, 690, 0, 0, 0, 315], [44, 0, 0, 0, 695, 0, 0, 0, 724, 0, 0, 0, 263]]\n",
      "[[313, 0, 0, 756, 0, 0, 522, 0, 0, 179, 0, 0, 0], [319, 0, 0, 742, 0, 0, 539, 0, 0, 170, 0, 0, 0]]\n",
      "[[51, 0, 0, 377, 0, 0, 695, 0, 0, 486, 0, 0, 196], [47, 0, 0, 402, 0, 0, 649, 0, 0, 518, 0, 0, 189]]\n",
      "[[55, 0, 0, 213, 0, 0, 462, 0, 0, 807, 0, 0, 263], [56, 0, 0, 215, 0, 0, 466, 0, 0, 809, 0, 0, 254]]\n"
     ]
    }
   ],
   "source": [
    "for Set in [1,3,4,5,6]:\n",
    "    print([histogram(df_Essay[df_Essay['essay_set']==Set]['norm_score1']),histogram(df_Essay[df_Essay['essay_set']==Set]['norm_score2'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7169197767600322\n",
      "0.769230064491969\n",
      "0.8509277825717176\n",
      "0.7526961695797694\n",
      "0.7764876632801161\n"
     ]
    }
   ],
   "source": [
    "for Set in [1,3,4,5,6]:\n",
    "    print(quadratic_weighted_kappa(df_Essay[df_Essay['essay_set']==Set]['norm_score1'],df_Essay[df_Essay['essay_set']==Set]['norm_score2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7172861726670788\n",
      "0.7708155194901584\n",
      "0.8509405766098397\n",
      "0.7527010280573946\n",
      "0.7765388466877478\n"
     ]
    }
   ],
   "source": [
    "for Set in [1,3,4,5,6]:\n",
    "    print(pearson_correlation(df_Essay[df_Essay['essay_set']==Set]['norm_score1'],df_Essay[df_Essay['essay_set']==Set]['norm_score2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3838326738270209\n",
      "4.329084588644264\n",
      "2.0694915254237287\n",
      "4.362880886426593\n",
      "3.85\n"
     ]
    }
   ],
   "source": [
    "for Set in [1,3,4,5,6]:\n",
    "    print(Mean_squared_error(df_Essay[df_Essay['essay_set']==Set]['norm_score1'],df_Essay[df_Essay['essay_set']==Set]['norm_score2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
