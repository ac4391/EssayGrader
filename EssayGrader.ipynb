{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP:\n",
    "The first half of this notebook may be used to train an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.utils import get_batches, shuffle, train_val_split, preds_to_scores, scores_to_preds\n",
    "from src.mlp import MLP\n",
    "from src.rnn import RNN\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='ac4391', api_key='79W1QqBEtqlkdL2DNrqi')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data. This is the training dataframe saved from the preprocessing notebook.\n",
    "data_path = './data/train_df.pkl'\n",
    "train_df = pd.read_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>rater1_domain1_norm</th>\n",
       "      <th>rater2_domain1_norm</th>\n",
       "      <th>norm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>236</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>387</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>204</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  rater1_domain1  rater2_domain1  domain1_score  \\\n",
       "0         1          1               4               4              8   \n",
       "1         2          1               5               4              9   \n",
       "2         3          1               4               3              7   \n",
       "4         5          1               4               4              8   \n",
       "5         6          1               4               4              8   \n",
       "\n",
       "                                        essays_embed  word_count  min_score  \\\n",
       "0  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         299        2.0   \n",
       "1  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         349        2.0   \n",
       "2  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         236        2.0   \n",
       "4  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         387        2.0   \n",
       "5  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         204        2.0   \n",
       "\n",
       "   max_score  rater1_domain1_norm  rater2_domain1_norm  norm_score  \n",
       "0       12.0                    4                    4           8  \n",
       "1       12.0                    5                    4           9  \n",
       "2       12.0                    4                    3           7  \n",
       "4       12.0                    4                    4           8  \n",
       "5       12.0                    4                    4           8  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To further isolate our data, we will only examine essays from a single set\n",
    "# Feel free to experiment with different essay sets!\n",
    "\n",
    "set = 1\n",
    "df = train_df.loc[train_df['essay_set'] == set]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should get a plot here to examine score distribution for this set\n",
    "\n",
    "# In order to avoid bias toward more common scores, we will limit the number\n",
    "# of essays from each scoring bucket to a set value\n",
    "score_df = None\n",
    "min_score = int(df['min_score'].min())\n",
    "max_score = int(df['max_score'].max())\n",
    "\n",
    "n_max = 100\n",
    "for i in range(min_score,max_score+1):\n",
    "    if score_df is None:\n",
    "        score_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "    else:\n",
    "        temp_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "        score_df = pd.concat([score_df, temp_df])\n",
    "df = score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 training essays, each of shape 426 x 200\n"
     ]
    }
   ],
   "source": [
    "# Extract essay vectors and corresponding scores\n",
    "X = np.array(df['essays_embed'])\n",
    "y = np.array(df['domain1_score'])\n",
    "X = np.stack(X, axis=0)\n",
    "print('There are {} training essays, each of shape {} x {}'.format(X.shape[0], X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These essays are the wrong shape to feed directly into the MLP. Therefore, each essay matrix needs to be flattened into a 1-D vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 training essays, each a vector of length 85200\n"
     ]
    }
   ],
   "source": [
    "X_flatten = np.reshape(X, [X.shape[0], -1])\n",
    "print('There are {} training essays, each a vector of length {}'.format(X_flatten.shape[0], X_flatten.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to shuffle the data and separate it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X_flatten, y)\n",
    "\n",
    "X_train, y_train, X_val, y_val = train_val_split(X, y, train_prop=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to transform the labels to the form that the network will predict. For example, in set 1, the essays are graded on a scale from 2-12, therefore there are 11 classes into which the network will try to classify each essay. However, the network will classify essays into the scale 0-10. Therefore, this step will perform this shift on the labels. If the scoring range already starts at 0, no shift is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shifted from a scale of (2,12) to (0,10)\n",
      "Validation labels shifted from a scale of (2,11) to (0,9)\n"
     ]
    }
   ],
   "source": [
    "if min_score != 0:\n",
    "    y_train_adj = scores_to_preds(y_train, min_score)\n",
    "    print('Training labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_train),max(y_train), min(y_train_adj), max(y_train_adj)))\n",
    "    y_val_adj = scores_to_preds(y_val, min_score)\n",
    "    print('Validation labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_val),max(y_val), min(y_val_adj), max(y_val_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_train_adj = y_train\n",
    "    y_val_adj = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the name of the model you're training here. The model will be saved to the 'model/' directory of this project. Then choose other parameters such as learning rate, number of training epochs, l2 regularization, dropout probability, and regression vs classification. All other parameters are derived and do not need to be set manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "model_name = 'mlp_set1'\n",
    "hidden_dims = [1024,256]\n",
    "weight_scale = 1e-2\n",
    "batch_size = 16\n",
    "n_epochs = 20\n",
    "l2_reg = 1e-4\n",
    "keep_prob = 0.8\n",
    "reg = False\n",
    "lr = 1e-4\n",
    "\n",
    "# Derived Parameters\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type='mlp')\n",
    "\n",
    "mlp_net = MLP(input_dim=input_dim, hidden_dims=hidden_dims, num_classes=num_classes, weight_scale=weight_scale,\\\n",
    "              l2_reg=l2_reg, keep_prob=keep_prob, regression=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, Batch 1 -- Loss: 3.047 Validation accuracy: 0.119\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 8 8 8 8 8 8 8 8 6 8 5 8 5 8 8 8 8 6 6\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, Batch 1 -- Loss: 2.199 Validation accuracy: 0.095\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 8 8 7 8 8 8 8 7 8 8 8 8 8 8 8 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, Batch 1 -- Loss: 1.681 Validation accuracy: 0.202\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 5 5 5 5 7 4 5 8 5 5 5 8 8 8 8 8 7 8 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, Batch 1 -- Loss: 1.453 Validation accuracy: 0.310\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 4 4 4 5 5 4 5 8 4 4 5 8 8 8 8 7 5 5 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, Batch 1 -- Loss: 1.278 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 5 5 6 4 6 8 4 5 4 8 7 8 8 7 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, Batch 1 -- Loss: 0.722 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 4 5 6 4 5 8 4 4 4 8 6 8 8 8 4 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, Batch 1 -- Loss: 0.419 Validation accuracy: 0.345\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 4 4 4 5 6 4 6 8 4 4 4 8 7 7 8 8 4 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, Batch 1 -- Loss: 0.334 Validation accuracy: 0.393\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 4 5 6 4 5 8 4 4 4 8 6 7 8 8 4 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, Batch 1 -- Loss: 0.319 Validation accuracy: 0.357\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 4 5 6 4 6 8 4 4 4 8 7 7 8 8 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, Batch 1 -- Loss: 0.409 Validation accuracy: 0.333\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 4 5 6 4 5 8 4 4 5 8 7 7 8 8 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, Batch 1 -- Loss: 0.295 Validation accuracy: 0.333\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 4 5 6 4 5 7 4 4 5 8 7 7 8 8 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, Batch 1 -- Loss: 0.290 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 4 5 6 4 5 7 4 4 5 8 7 7 8 8 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, Batch 1 -- Loss: 0.495 Validation accuracy: 0.357\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 4 5 6 4 5 8 4 4 5 8 7 7 8 8 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, Batch 1 -- Loss: 0.443 Validation accuracy: 0.369\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 4 5 6 4 5 7 4 4 5 8 7 7 8 7 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, Batch 1 -- Loss: 0.122 Validation accuracy: 0.333\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 4 5 6 4 6 7 4 4 4 8 7 8 8 8 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, Batch 1 -- Loss: 0.231 Validation accuracy: 0.369\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 4 5 6 4 6 8 4 4 4 8 7 7 8 8 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, Batch 1 -- Loss: 0.112 Validation accuracy: 0.357\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 4 5 6 3 6 8 3 4 4 8 6 7 8 7 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, Batch 1 -- Loss: 0.348 Validation accuracy: 0.357\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 4 5 6 4 6 8 3 4 5 8 7 7 8 8 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, Batch 1 -- Loss: 0.107 Validation accuracy: 0.345\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 4 5 6 4 5 7 3 4 5 8 6 7 8 8 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, Batch 1 -- Loss: 0.099 Validation accuracy: 0.345\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 4 5 6 4 6 8 2 4 5 8 7 7 8 8 5 6 8\n",
      "Actual:  4 5 2 4 5 6 0 5 6 0 5 4 9 6 6 7 7 4 6 8\n",
      "Best validation accuracy over the training period was: 0.4166666567325592%\n"
     ]
    }
   ],
   "source": [
    "train_loss_hist, val_loss_hist = mlp_net.train(gen=batch_gen, X_val=X_val, y_val=y_val_adj, n_epochs=n_epochs, n_batches=n_batches, lr=lr,\\\n",
    "                                               save_every_n=5, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Loss data for plotting\n",
    "x = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "for k,v in train_loss_hist.items():\n",
    "    x.append(k[0]-1+k[1]/n_batches)\n",
    "    train_loss.append(v)\n",
    "    val_loss.append(val_loss_hist[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~ac4391/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ac4391/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "Train_loss = go.Scatter(\n",
    "    x=x,\n",
    "    y=train_loss\n",
    ")\n",
    "Val_loss = go.Scatter(\n",
    "    x=x,\n",
    "    y=val_loss\n",
    ")\n",
    "\n",
    "data = [Train_loss, Val_loss]\n",
    "py.iplot(data, filename='basic-area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/mlp_set1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/mlp_set1\n"
     ]
    }
   ],
   "source": [
    "preds = mlp_net.predict('./model/'+model_name, X_val)\n",
    "\n",
    "# We need to map predictions from classes in the model to actual scores\n",
    "preds = preds_to_scores(preds, min_score=min_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quadratic weighted kappa score for set 1 using mlp_set1 is : 0.7934023033378881\n"
     ]
    }
   ],
   "source": [
    "from src.preprocess import quadratic_weighted_kappa\n",
    "\n",
    "k = quadratic_weighted_kappa(y_val, preds)\n",
    "\n",
    "print('The quadratic weighted kappa score for set {} using {} is : {}'\\\n",
    "     .format(set, model_name, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN:\n",
    "The second half of this notebook may be used for training an RNN - specifically an LSTM or GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>rater1_domain1_norm</th>\n",
       "      <th>rater2_domain1_norm</th>\n",
       "      <th>norm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>236</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>387</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>204</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  rater1_domain1  rater2_domain1  domain1_score  \\\n",
       "0         1          1               4               4              8   \n",
       "1         2          1               5               4              9   \n",
       "2         3          1               4               3              7   \n",
       "4         5          1               4               4              8   \n",
       "5         6          1               4               4              8   \n",
       "\n",
       "                                        essays_embed  word_count  min_score  \\\n",
       "0  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         299        2.0   \n",
       "1  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         349        2.0   \n",
       "2  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         236        2.0   \n",
       "4  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         387        2.0   \n",
       "5  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         204        2.0   \n",
       "\n",
       "   max_score  rater1_domain1_norm  rater2_domain1_norm  norm_score  \n",
       "0       12.0                    4                    4           8  \n",
       "1       12.0                    5                    4           9  \n",
       "2       12.0                    4                    3           7  \n",
       "4       12.0                    4                    4           8  \n",
       "5       12.0                    4                    4           8  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the data\n",
    "data_path = './data/train_df.pkl'\n",
    "train_df = pd.read_pickle(data_path)\n",
    "\n",
    "# To further isolate our data, we will only examine essays from a single set\n",
    "# Feel free to experiment with different essay sets!\n",
    "set = 1\n",
    "df = train_df.loc[train_df['essay_set'] == set]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to avoid bias toward more common scores, we will limit the number\n",
    "# of essays from each scoring bucket to a set value\n",
    "score_df = None\n",
    "min_score = int(df['min_score'].min())\n",
    "max_score = int(df['max_score'].max())\n",
    "\n",
    "n_max = 100\n",
    "for i in range(min_score,max_score+1):\n",
    "    if score_df is None:\n",
    "        score_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "    else:\n",
    "        temp_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "        score_df = pd.concat([score_df, temp_df])\n",
    "df = score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 training essays, each of shape 426 x 200\n"
     ]
    }
   ],
   "source": [
    "# Extract essay vectors and corresponding scores\n",
    "X = np.array(df['essays_embed'])\n",
    "y = np.array(df['domain1_score'])\n",
    "X = np.stack(X, axis=0)\n",
    "print('There are {} training essays, each of shape {} x {}'.format(X.shape[0], X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to shuffle the data and separate it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)\n",
    "X_train, y_train, X_val, y_val = train_val_split(X, y, train_prop=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to transform the labels to the form that the network will predict. For example, in set 1, the essays are graded on a scale from 2-12, therefore there are 11 classes into which the network will try to classify each essay. However, the network will classify essays into the scale 0-10. Therefore, this step will perform this shift on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shifted from a scale of (2,12) to (0,10)\n",
      "Validation labels shifted from a scale of (2,12) to (0,10)\n"
     ]
    }
   ],
   "source": [
    "if min_score != 0:\n",
    "    y_train_adj = scores_to_preds(y_train, min_score)\n",
    "    print('Training labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_train),max(y_train), min(y_train_adj), max(y_train_adj)))\n",
    "    y_val_adj = scores_to_preds(y_val, min_score)\n",
    "    print('Validation labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_val),max(y_val), min(y_val_adj), max(y_val_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_train_adj = y_train\n",
    "    y_val_adj = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "model_name = 'gru_set4'\n",
    "batch_size = 32\n",
    "cell_type = 'gru'\n",
    "rnn_size = 256\n",
    "lr = 5e-3\n",
    "n_epochs = 20\n",
    "keep_prob = 0.8\n",
    "\n",
    "# Derived Parameters\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "seq_length = X_train.shape[1]\n",
    "embed_size = X_train.shape[2]\n",
    "\n",
    "X_val_t = X_val[:batch_size]\n",
    "y_val_t = y_val_adj[:batch_size]\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type=cell_type)\n",
    "\n",
    "rnn_net = RNN(num_classes, batch_size, seq_length, embed_size, cell_type=cell_type,\n",
    "                 rnn_size=rnn_size, num_layers=2, learning_rate=lr, train_keep_prob=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, step 5 loss: 2.3516  validation accuracy: 0.34375  0.4739 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 7 7 7 7 7 7 7 7 7 4 7 7 7 7 4 7 9 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 1, step 10 loss: 2.0747  validation accuracy: 0.125  0.6476 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 1, step 15 loss: 1.9616  validation accuracy: 0.1875  0.5187 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 6 6 6 6 7 6 6 6 6 6 7 6 6 6 6 7 6 7 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, step 5 loss: 1.7476  validation accuracy: 0.28125  0.6567 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 5 5 5 5 8 5 5 5 5 5 8 5 5 5 5 8 5 8 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 2, step 10 loss: 1.5554  validation accuracy: 0.25  0.5419 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 5 5 6 7 5 5 5 5 5 7 5 6 5 6 7 5 7 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 2, step 15 loss: 1.7117  validation accuracy: 0.1875  0.5345 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 4 6 6 6 4 4 6 6 8 4 6 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, step 5 loss: 1.6732  validation accuracy: 0.28125  0.5535 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 6 6 7 7 6 6 6 6 6 8 6 7 6 7 8 6 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 3, step 10 loss: 1.5362  validation accuracy: 0.1875  0.5006 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 5 4 4 8 8 4 4 4 5 4 8 4 8 5 8 8 4 8 4\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 3, step 15 loss: 1.5569  validation accuracy: 0.4375  0.5057 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 4 4 7 7 5 4 4 6 6 7 4 7 7 7 7 4 8 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, step 5 loss: 1.3883  validation accuracy: 0.25  0.5028 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 6 4 4 6 7 6 4 4 6 6 8 4 6 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 4, step 10 loss: 2.1951  validation accuracy: 0.0625  0.5135 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 3 6 5 5 6 6 6 5 6 6 8 6 3 6 3 8 6 8 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 4, step 15 loss: 2.0993  validation accuracy: 0.125  0.5077 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 4 4 4 4 7 4 4 4 4 4 8 4 4 4 4 8 4 8 4\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, step 5 loss: 2.0429  validation accuracy: 0.1875  0.5121 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   9 8 4 4 8 8 7 4 4 7 7 8 4 8 8 8 9 4 9 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 5, step 10 loss: 1.7669  validation accuracy: 0.15625  0.5556 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 4 6 6 6 4 4 6 6 6 4 6 6 6 6 4 6 4\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 5, step 15 loss: 1.6294  validation accuracy: 0.1875  0.5227 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 4 4 8 8 6 4 4 6 6 8 4 8 8 8 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, step 5 loss: 1.3605  validation accuracy: 0.375  0.5377 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 4 4 7 7 5 4 4 7 7 8 4 7 7 7 8 4 8 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 6, step 10 loss: 1.3217  validation accuracy: 0.21875  0.5982 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 6 6 4 6 7 6 5 4 6 6 8 5 6 6 6 9 4 9 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 6, step 15 loss: 1.8758  validation accuracy: 0.21875  0.5375 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 6 4 4 6 7 6 4 4 6 6 8 4 6 6 6 8 4 8 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, step 5 loss: 1.3120  validation accuracy: 0.4375  0.5130 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 7 5 4 7 7 7 4 4 7 7 8 5 7 7 7 8 4 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 7, step 10 loss: 1.3120  validation accuracy: 0.3125  0.5020 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 6 4 4 6 7 5 4 4 5 5 8 4 6 6 6 8 4 8 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 7, step 15 loss: 1.2542  validation accuracy: 0.28125  0.4954 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 6 5 4 6 7 6 5 5 6 6 8 5 6 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, step 5 loss: 1.3676  validation accuracy: 0.21875  0.5076 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 6 6 4 6 7 6 6 4 6 6 8 5 6 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 8, step 10 loss: 1.6158  validation accuracy: 0.25  0.5063 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 5 4 6 7 6 5 4 6 6 8 5 7 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 8, step 15 loss: 1.2575  validation accuracy: 0.34375  0.5026 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 4 4 7 7 6 4 4 6 6 8 4 7 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, step 5 loss: 1.1078  validation accuracy: 0.1875  0.4955 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 6 5 4 6 7 6 5 4 6 6 8 5 6 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 9, step 10 loss: 1.3813  validation accuracy: 0.21875  0.5216 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 6 4 2 6 7 6 4 2 6 6 8 4 6 6 6 8 2 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 9, step 15 loss: 1.1294  validation accuracy: 0.25  0.5181 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 5 4 7 7 6 5 4 6 6 7 5 7 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, step 5 loss: 1.2709  validation accuracy: 0.15625  0.5066 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 9 5 4 8 8 6 5 4 8 6 8 5 8 8 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 10, step 10 loss: 1.0348  validation accuracy: 0.3125  0.5026 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 6 5 4 6 7 6 5 4 6 6 7 5 6 6 6 7 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 10, step 15 loss: 1.2076  validation accuracy: 0.34375  0.6131 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 4 4 7 7 6 5 4 6 6 8 4 7 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, step 5 loss: 1.0788  validation accuracy: 0.3125  0.6465 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 5 4 6 7 6 5 4 6 6 8 5 7 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 11, step 10 loss: 1.0135  validation accuracy: 0.3125  0.5121 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 9 5 0 8 7 6 5 4 6 6 8 5 7 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 11, step 15 loss: 1.1337  validation accuracy: 0.28125  0.5161 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 9 5 2 7 7 6 5 4 6 6 8 5 7 6 6 8 2 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, step 5 loss: 0.7008  validation accuracy: 0.3125  0.5095 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 6 5 2 6 7 6 5 4 6 6 8 4 6 6 6 8 4 8 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 12, step 10 loss: 0.6960  validation accuracy: 0.21875  0.5313 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 9 5 0 8 7 6 5 2 6 6 8 4 7 6 6 8 0 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 12, step 15 loss: 0.9756  validation accuracy: 0.28125  0.5220 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 6 5 2 6 7 6 5 4 6 5 7 4 6 6 5 8 2 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, step 5 loss: 0.6422  validation accuracy: 0.3125  0.5218 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 9 5 2 7 7 6 5 4 6 6 8 4 7 6 5 8 4 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 13, step 10 loss: 1.6688  validation accuracy: 0.28125  0.5056 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 9 5 0 7 7 6 5 4 6 6 7 5 7 6 6 8 4 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, step 15 loss: 1.3781  validation accuracy: 0.28125  0.5105 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 9 5 4 7 7 6 5 5 6 7 8 5 7 6 6 8 4 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, step 5 loss: 0.7739  validation accuracy: 0.1875  0.6192 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 9 4 4 7 7 6 5 4 6 6 8 4 7 6 6 8 4 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 14, step 10 loss: 0.8512  validation accuracy: 0.1875  0.5051 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   9 9 4 4 7 7 6 4 4 6 6 7 4 6 6 4 8 4 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 14, step 15 loss: 0.9265  validation accuracy: 0.28125  0.5078 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 4 4 6 7 5 5 4 6 6 7 5 7 6 5 8 5 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, step 5 loss: 0.5972  validation accuracy: 0.25  0.5113 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 9 5 4 8 7 6 5 4 7 6 8 5 7 7 6 8 5 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 15, step 10 loss: 0.6223  validation accuracy: 0.125  0.5369 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 9 4 4 6 7 6 5 4 6 6 7 4 6 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 15, step 15 loss: 0.5864  validation accuracy: 0.1875  0.5141 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 9 5 4 6 7 6 5 4 6 6 8 4 6 6 6 8 4 8 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, step 5 loss: 0.3838  validation accuracy: 0.25  0.5320 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 9 5 4 8 7 6 5 5 6 7 8 5 7 7 6 8 4 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 16, step 10 loss: 0.3271  validation accuracy: 0.28125  0.4987 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 9 5 0 7 7 6 5 4 6 6 8 5 6 6 6 8 4 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 16, step 15 loss: 0.5093  validation accuracy: 0.25  0.4884 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 9 4 4 6 7 6 5 4 6 6 7 4 6 6 5 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, step 5 loss: 0.3650  validation accuracy: 0.25  0.5233 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   9 6 5 4 6 7 6 5 4 6 6 7 5 6 6 5 8 4 8 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 17, step 10 loss: 0.8244  validation accuracy: 0.28125  0.5030 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 9 5 2 7 7 6 5 4 6 7 8 5 7 6 5 8 2 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 17, step 15 loss: 1.0648  validation accuracy: 0.25  0.4962 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 9 6 4 6 7 6 5 4 6 6 7 5 6 6 6 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, step 5 loss: 0.7430  validation accuracy: 0.21875  0.4977 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 9 4 4 6 7 6 5 4 6 7 8 4 7 5 4 8 4 8 6\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 18, step 10 loss: 0.6032  validation accuracy: 0.1875  0.4970 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 6 4 4 6 7 6 5 4 6 6 7 5 6 6 5 8 4 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 18, step 15 loss: 0.4929  validation accuracy: 0.1875  0.5814 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 9 5 4 6 7 6 6 4 6 6 8 5 6 6 6 8 5 8 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, step 5 loss: 0.3706  validation accuracy: 0.21875  0.5100 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 9 4 4 8 7 6 5 4 6 6 8 5 7 6 6 8 0 8 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 19, step 10 loss: 0.2164  validation accuracy: 0.25  0.5053 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 9 5 4 6 7 6 5 4 6 6 8 4 7 6 6 8 4 8 5\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 19, step 15 loss: 0.5681  validation accuracy: 0.21875  0.5102 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 6 6 2 6 7 6 5 4 6 6 7 5 6 6 6 8 4 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, step 5 loss: 0.2936  validation accuracy: 0.3125  0.5453 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 6 5 2 6 7 6 5 4 6 6 8 5 6 6 6 8 2 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 20, step 10 loss: 0.2673  validation accuracy: 0.28125  0.5251 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 9 5 4 6 7 6 5 4 6 6 8 5 6 6 6 8 4 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Epoch 20, step 15 loss: 0.2910  validation accuracy: 0.25  0.6028 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 9 6 4 7 7 6 6 4 6 7 8 5 6 6 6 8 4 8 7\n",
      "Actual:  8 7 5 3 7 8 5 4 4 6 7 5 7 7 7 7 7 1 10 8\n",
      "Best validation accuracy over the training period was: 0.4375%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = rnn_net.train(batch_gen, X_val_t, y_val_t,\\\n",
    "                                              n_epochs, n_batches, save_every_n=5,\\\n",
    "                                              model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Loss data for plotting\n",
    "x = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "for k,v in train_loss_hist.items():\n",
    "    x.append(k[0]-1+k[1]/n_batches)\n",
    "    train_loss.append(v)\n",
    "    val_loss.append(val_loss_hist[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~ac4391/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ac4391/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "Train_loss = go.Scatter(\n",
    "    x=x,\n",
    "    y=train_loss,\n",
    "    fill='tozeroy'\n",
    ")\n",
    "Val_loss = go.Scatter(\n",
    "    x=x,\n",
    "    y=val_loss,\n",
    "    fill='tonexty'\n",
    ")\n",
    "\n",
    "data = [Train_loss, Val_loss]\n",
    "py.iplot(data, filename='basic-area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/gru_set4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/gru_set4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running network predictions\n"
     ]
    }
   ],
   "source": [
    "batch_size = X_val.shape[0]\n",
    "seq_length = X_val.shape[1]\n",
    "embed_size = X_val.shape[2]\n",
    "\n",
    "pred_net = RNN(num_classes, batch_size, seq_length, embed_size, cell_type=cell_type,\n",
    "                 rnn_size=rnn_size, num_layers=2, learning_rate=lr, train_keep_prob=1)\n",
    "preds = pred_net.predict('./model/'+model_name, X_val)\n",
    "preds = preds_to_scores(preds, min_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quadratic weighted kappa score for set 1 using gru_set4 is : 0.6967093235831808\n"
     ]
    }
   ],
   "source": [
    "from src.preprocess import quadratic_weighted_kappa\n",
    "k = quadratic_weighted_kappa(preds[0], y_val)\n",
    "\n",
    "print('The quadratic weighted kappa score for set {} using {} is : {}'\\\n",
    "     .format(set, model_name, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
