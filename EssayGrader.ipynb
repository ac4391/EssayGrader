{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP:\n",
    "The first half of this notebook may be used to train an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from src.utils import get_batches, shuffle, train_val_split, preds_to_scores, scores_to_preds\n",
    "from src.mlp import MLP\n",
    "from src.rnn import RNN\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data. This is the training dataframe saved from the preprocessing notebook.\n",
    "data_path = './data/train_df.pkl'\n",
    "train_df = pd.read_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>norm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>5978</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.045849, 0.085148, -0.12276, -0.39789, 0.7...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>5980</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.52791, 0.34362, 0.15408, 0.24317, -0.39083...</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587</th>\n",
       "      <td>5982</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.46549, 0.1526, -0.52178, -0.40354, -0.1565...</td>\n",
       "      <td>104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588</th>\n",
       "      <td>5983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.66193, 0.16192, -0.090129, -0.59287, 0.153...</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>5985</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.14956, -0.25978, 0.66754, 0.83551, 0.41318...</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>norm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>5978</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.045849, 0.085148, -0.12276, -0.39789, 0.7...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>5980</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.52791, 0.34362, 0.15408, 0.24317, -0.39083...</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587</th>\n",
       "      <td>5982</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.46549, 0.1526, -0.52178, -0.40354, -0.1565...</td>\n",
       "      <td>104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588</th>\n",
       "      <td>5983</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.66193, 0.16192, -0.090129, -0.59287, 0.153...</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>5985</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.14956, -0.25978, 0.66754, 0.83551, 0.41318...</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To further isolate our data, we will only examine essays from a single set\n",
    "# Feel free to experiment with different essay sets!\n",
    "\n",
    "set = 3\n",
    "df = train_df.loc[train_df['essay_set'] == set]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should get a plot here to examine score distribution for this set\n",
    "\n",
    "# In order to avoid bias toward more common scores, we will limit the number\n",
    "# of essays from each scoring bucket to a set value\n",
    "score_df = None\n",
    "min_score = int(df['min_score'].min())\n",
    "max_score = int(df['max_score'].max())\n",
    "\n",
    "n_max = 500\n",
    "for i in range(min_score,max_score+1):\n",
    "    if score_df is None:\n",
    "        score_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "    else:\n",
    "        temp_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "        score_df = pd.concat([score_df, temp_df])\n",
    "df = score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 979 training essays, each of shape 137 x 200\n"
     ]
    }
   ],
   "source": [
    "# Extract essay vectors and corresponding scores\n",
    "X = np.array(df['essays_embed'])\n",
    "y = np.array(df['domain1_score'])\n",
    "X = np.stack(X, axis=0)\n",
    "print('There are {} training essays, each of shape {} x {}'.format(X.shape[0], X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These essays are too large to feed directly into an MLP. Therefore, the next steps are to flatten the essays and subsequently perform Principle Component Analysis (PCA) in order to reduce the dimensionality. More info on PCA here if you are unfamiliar: https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After PCA, there are 979 essays each represented by a 300 length vector\n"
     ]
    }
   ],
   "source": [
    "X_flatten = np.reshape(X, [X.shape[0], -1])\n",
    "X_shuff, y = shuffle(X_flatten, y)\n",
    "\n",
    "# Consider adding an assertion that n_components must be less than\n",
    "# the number of essays in X_shuff\n",
    "\n",
    "# Train the PCA model. Feel free to experiment with different numbers of \n",
    "# principle components to optimize the model\n",
    "X_shuff = X_shuff[:300]\n",
    "pca = PCA(n_components=300)\n",
    "pca.fit(X_shuff)\n",
    "\n",
    "# Perform the PCA transformation on the flattened data\n",
    "X_PCA = pca.transform(X_flatten)\n",
    "print('After PCA, there are {} essays each represented by a {} length vector'\\\n",
    "      .format(X_PCA.shape[0], X_PCA.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to shuffle the data and separate it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X_PCA, y)\n",
    "X_train, y_train, X_val, y_val = train_val_split(X, y, train_prop=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to transform the labels to the form that the network will predict. For example, in set 1, the essays are graded on a scale from 2-12, therefore there are 11 classes into which the network will try to classify each essay. However, the network will classify essays into the scale 0-10. Therefore, this step will perform this shift on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shifted from a scale of (0,3) to (0,3)\nValidation labels shifted from a scale of (0,3) to (0,3)\n"
     ]
    }
   ],
   "source": [
    "y_train_adj = scores_to_preds(y_train, min_score)\n",
    "print('Training labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "      .format(min(y_train),max(y_train), min(y_train_adj), max(y_train_adj)))\n",
    "y_val_adj = scores_to_preds(y_val, min_score)\n",
    "print('Validation labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "      .format(min(y_val),max(y_val), min(y_val_adj), max(y_val_adj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = max_score-min_score + 1\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type='mlp')\n",
    "\n",
    "mlp_net = MLP(input_dim=input_dim, hidden_dims=[128,32], num_classes=num_classes, regression=False, l2_reg=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 1 -- Loss: 0.8917707800865173 Validation accuracy: 0.4109589159488678\n[2 2 2 2 1 2 2 2 1 2 2 1 2 1 2 2 1 2 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\nBest validation accuracy! accuracy: 0.4109589159488678%\nModel Saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Batch 1 -- Loss: 0.2889643609523773 Validation accuracy: 0.4383561611175537\n[1 1 1 1 1 1 2 2 1 1 2 1 2 1 1 1 3 1 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\nBest validation accuracy! accuracy: 0.4383561611175537%\nModel Saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Batch 1 -- Loss: 0.29769450426101685 Validation accuracy: 0.4041095972061157\n[1 1 1 1 1 2 2 2 1 1 2 2 2 1 1 2 3 1 1 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Batch 1 -- Loss: 0.10581934452056885 Validation accuracy: 0.39726027846336365\n[1 1 1 1 1 2 2 2 1 1 2 2 2 1 1 1 3 1 1 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Batch 1 -- Loss: 0.13126574456691742 Validation accuracy: 0.4041095972061157\n[1 1 1 1 3 2 2 1 1 1 2 2 2 1 1 1 3 1 1 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Batch 1 -- Loss: 0.013781010173261166 Validation accuracy: 0.36986300349235535\n[1 1 1 1 3 2 2 1 2 1 2 3 2 1 1 1 3 1 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Batch 1 -- Loss: 0.10488999634981155 Validation accuracy: 0.3835616409778595\n[1 1 1 1 3 2 2 1 2 1 2 3 2 1 1 1 3 1 1 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Batch 1 -- Loss: 0.17736192047595978 Validation accuracy: 0.3835616409778595\n[1 1 1 1 3 2 2 1 2 1 2 3 2 1 1 1 3 1 1 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Batch 1 -- Loss: 0.04077163338661194 Validation accuracy: 0.4109589159488678\n[1 1 1 1 3 2 2 1 2 1 2 2 2 1 1 1 3 1 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Batch 1 -- Loss: 0.009091063402593136 Validation accuracy: 0.4109589159488678\n[1 1 1 1 1 2 2 1 2 1 2 2 2 1 1 1 3 1 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110, Batch 1 -- Loss: 0.00876113586127758 Validation accuracy: 0.4109589159488678\n[1 1 1 1 1 2 2 1 2 1 2 2 2 1 1 1 3 1 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, Batch 1 -- Loss: 0.00806284137070179 Validation accuracy: 0.4109589159488678\n[1 1 1 2 2 2 2 1 2 1 2 2 2 1 1 1 3 1 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130, Batch 1 -- Loss: 0.007894589565694332 Validation accuracy: 0.4178082048892975\n[1 1 1 2 2 2 2 1 2 1 2 2 2 1 1 1 3 1 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140, Batch 1 -- Loss: 0.0074392505921423435 Validation accuracy: 0.4178082048892975\n[1 1 1 2 2 2 2 1 3 1 2 2 2 1 1 1 3 1 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, Batch 1 -- Loss: 0.006933273747563362 Validation accuracy: 0.42465752363204956\n[1 1 1 2 2 2 2 1 3 1 2 2 2 1 1 1 3 1 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160, Batch 1 -- Loss: 0.0066261859610676765 Validation accuracy: 0.4383561611175537\n[1 1 1 2 2 2 2 1 3 1 2 2 2 1 1 1 3 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170, Batch 1 -- Loss: 0.00647774338722229 Validation accuracy: 0.4452054798603058\n[1 1 1 2 2 2 2 1 3 1 2 2 2 1 1 1 3 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\nBest validation accuracy! accuracy: 0.4452054798603058%\nModel Saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180, Batch 1 -- Loss: 0.005972813814878464 Validation accuracy: 0.4452054798603058\n[1 1 1 2 2 2 2 1 3 1 2 3 2 1 1 1 3 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190, Batch 1 -- Loss: 0.005702212452888489 Validation accuracy: 0.43150684237480164\n[1 1 1 2 2 2 2 1 3 1 2 3 2 1 1 1 3 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Batch 1 -- Loss: 0.005618404597043991 Validation accuracy: 0.4383561611175537\n[1 1 1 2 2 2 2 1 3 1 2 3 2 1 1 1 3 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210, Batch 1 -- Loss: 0.005199503619223833 Validation accuracy: 0.43150684237480164\n[1 1 1 2 2 2 2 1 3 1 2 3 2 1 1 1 3 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220, Batch 1 -- Loss: 0.004908915143460035 Validation accuracy: 0.4109589159488678\n[1 1 1 2 2 2 2 1 3 1 2 3 2 1 1 1 3 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230, Batch 1 -- Loss: 0.004739752504974604 Validation accuracy: 0.39726027846336365\n[1 1 1 2 2 2 2 2 3 1 2 3 2 1 1 1 3 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240, Batch 1 -- Loss: 0.00463905232027173 Validation accuracy: 0.3904109597206116\n[1 1 1 2 2 2 2 2 3 1 2 3 2 1 1 1 3 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250, Batch 1 -- Loss: 0.004337003920227289 Validation accuracy: 0.3835616409778595\n[1 1 1 2 2 2 2 2 3 1 2 3 2 1 1 1 3 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260, Batch 1 -- Loss: 0.0041592977941036224 Validation accuracy: 0.39726027846336365\n[1 1 1 2 2 2 2 2 3 1 2 3 2 1 1 1 3 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270, Batch 1 -- Loss: 0.024469729512929916 Validation accuracy: 0.4383561611175537\n[1 1 1 1 2 2 2 1 1 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280, Batch 1 -- Loss: 0.010750755667686462 Validation accuracy: 0.4452054798603058\n[1 1 1 1 2 2 2 1 1 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290, Batch 1 -- Loss: 0.009202134795486927 Validation accuracy: 0.45890411734580994\n[1 1 1 2 2 2 1 1 1 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\nBest validation accuracy! accuracy: 0.45890411734580994%\nModel Saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300, Batch 1 -- Loss: 0.008234532549977303 Validation accuracy: 0.45890411734580994\n[1 1 1 2 2 2 1 1 1 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310, Batch 1 -- Loss: 0.00799835380166769 Validation accuracy: 0.45890411734580994\n[1 1 1 2 2 2 1 1 1 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320, Batch 1 -- Loss: 0.00788875576108694 Validation accuracy: 0.45205479860305786\n[1 1 1 2 2 2 1 1 1 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330, Batch 1 -- Loss: 0.0076670353300869465 Validation accuracy: 0.45205479860305786\n[1 1 1 2 2 2 1 1 1 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340, Batch 1 -- Loss: 0.007765050046145916 Validation accuracy: 0.4383561611175537\n[1 1 1 2 2 2 1 1 2 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350, Batch 1 -- Loss: 0.007505909539759159 Validation accuracy: 0.4383561611175537\n[1 1 1 2 2 2 1 1 2 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360, Batch 1 -- Loss: 0.007398518733680248 Validation accuracy: 0.4452054798603058\n[1 1 1 2 2 2 1 1 2 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370, Batch 1 -- Loss: 0.007235968019813299 Validation accuracy: 0.4452054798603058\n[1 1 1 2 2 2 1 1 2 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380, Batch 1 -- Loss: 0.007136772386729717 Validation accuracy: 0.4452054798603058\n[1 1 1 2 2 2 1 1 2 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390, Batch 1 -- Loss: 0.00683285016566515 Validation accuracy: 0.4452054798603058\n[1 1 1 2 2 2 1 1 2 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, Batch 1 -- Loss: 0.006639535538852215 Validation accuracy: 0.4383561611175537\n[1 1 1 2 2 2 1 1 2 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410, Batch 1 -- Loss: 0.0063898940570652485 Validation accuracy: 0.4383561611175537\n[1 1 1 2 2 2 1 1 2 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420, Batch 1 -- Loss: 0.006227334029972553 Validation accuracy: 0.4383561611175537\n[1 1 1 2 2 2 1 1 3 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430, Batch 1 -- Loss: 0.005969890393316746 Validation accuracy: 0.4383561611175537\n[1 1 1 2 2 2 1 1 3 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440, Batch 1 -- Loss: 0.005764879751950502 Validation accuracy: 0.4383561611175537\n[1 1 1 2 2 2 1 1 3 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450, Batch 1 -- Loss: 0.0055386899039149284 Validation accuracy: 0.43150684237480164\n[1 1 1 2 2 2 1 1 3 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460, Batch 1 -- Loss: 0.005315128713846207 Validation accuracy: 0.43150684237480164\n[1 1 1 2 2 2 1 1 3 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470, Batch 1 -- Loss: 0.005101803690195084 Validation accuracy: 0.43150684237480164\n[1 1 1 2 2 2 1 1 3 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480, Batch 1 -- Loss: 0.004919599741697311 Validation accuracy: 0.4178082048892975\n[1 1 1 2 2 2 2 1 3 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490, Batch 1 -- Loss: 0.004662978928536177 Validation accuracy: 0.4178082048892975\n[1 1 1 2 2 2 2 1 3 2 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Batch 1 -- Loss: 0.004472282249480486 Validation accuracy: 0.42465752363204956\n[1 1 1 2 2 2 2 1 3 1 2 3 2 1 1 1 2 3 2 2]\n[2 1 2 2 3 2 1 1 1 1 3 3 2 2 1 2 2 2 2 2]\nBest validation accuracy over the training period was: 0.45890411734580994%\n"
     ]
    }
   ],
   "source": [
    "mlp_net.train(gen=batch_gen, X_val=X_val, y_val=y_val_adj, n_epochs=500, n_batches=n_batches, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/best_model_mlp\n"
     ]
    }
   ],
   "source": [
    "preds = mlp_net.predict('./model/best_model_mlp', X_val)\n",
    "# We need to map predictions from classes in the model to actual scores\n",
    "preds = preds_to_scores(preds, min_score=min_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07015079142081104"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.preprocess import quadratic_weighted_kappa\n",
    "\n",
    "quadratic_weighted_kappa(y_val, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN:\n",
    "The second half of this notebook may be used for training an RNN - specifically an LSTM or GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>norm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>8863</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.46765, 0.46369, 0.21761, -0.63619, 0.2019...</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>8864</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.15637, -0.40361, -0.29629, -0.34259, -0.18...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>8865</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[[-0.46765, 0.46369, 0.21761, -0.63619, 0.2019...</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>8866</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-0.46765, 0.46369, 0.21761, -0.63619, 0.2019...</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5313</th>\n",
       "      <td>8867</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-0.46765, 0.46369, 0.21761, -0.63619, 0.2019...</td>\n",
       "      <td>104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>norm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>8863</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.46765, 0.46369, 0.21761, -0.63619, 0.2019...</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>8864</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.15637, -0.40361, -0.29629, -0.34259, -0.18...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>8865</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[[-0.46765, 0.46369, 0.21761, -0.63619, 0.2019...</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>8866</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-0.46765, 0.46369, 0.21761, -0.63619, 0.2019...</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5313</th>\n",
       "      <td>8867</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-0.46765, 0.46369, 0.21761, -0.63619, 0.2019...</td>\n",
       "      <td>104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the data\n",
    "data_path = './data/train_df.pkl'\n",
    "train_df = pd.read_pickle(data_path)\n",
    "\n",
    "# To further isolate our data, we will only examine essays from a single set\n",
    "# Feel free to experiment with different essay sets!\n",
    "set = 4\n",
    "df = train_df.loc[train_df['essay_set'] == set]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to avoid bias toward more common scores, we will limit the number\n",
    "# of essays from each scoring bucket to a set value\n",
    "score_df = None\n",
    "min_score = int(df['min_score'].min())\n",
    "max_score = int(df['max_score'].max())\n",
    "\n",
    "n_max = 500\n",
    "for i in range(min_score,max_score+1):\n",
    "    if score_df is None:\n",
    "        score_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "    else:\n",
    "        temp_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "        score_df = pd.concat([score_df, temp_df])\n",
    "df = score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1201 training essays, each of shape 120 x 200\n"
     ]
    }
   ],
   "source": [
    "# Extract essay vectors and corresponding scores\n",
    "X = np.array(df['essays_embed'])\n",
    "y = np.array(df['domain1_score'])\n",
    "X = np.stack(X, axis=0)\n",
    "print('There are {} training essays, each of shape {} x {}'.format(X.shape[0], X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to shuffle the data and separate it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)\n",
    "X_train, y_train, X_val, y_val = train_val_split(X, y, train_prop=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to transform the labels to the form that the network will predict. For example, in set 1, the essays are graded on a scale from 2-12, therefore there are 11 classes into which the network will try to classify each essay. However, the network will classify essays into the scale 0-10. Therefore, this step will perform this shift on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shifted from a scale of (0,3) to (0,3)\nValidation labels shifted from a scale of (0,3) to (0,3)\n"
     ]
    }
   ],
   "source": [
    "y_train_adj = scores_to_preds(y_train, min_score)\n",
    "print('Training labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "      .format(min(y_train),max(y_train), min(y_train_adj), max(y_train_adj)))\n",
    "y_val_adj = scores_to_preds(y_val, min_score)\n",
    "print('Validation labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "      .format(min(y_val),max(y_val), min(y_val_adj), max(y_val_adj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "num_classes = max_score-min_score + 1\n",
    "seq_length = X_train.shape[1]\n",
    "embed_size = X_train.shape[2]\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type='gru')\n",
    "\n",
    "my_net = RNN(num_classes, batch_size, seq_length, embed_size=embed_size, cell_type='gru',\n",
    "                 rnn_size=128, num_layers=2, learning_rate=0.005, train_keep_prob=1, sampling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\nInitializing training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 10 loss: 1.0048  validation accuracy: 0.375  0.1702 sec/batch\nBest validation accuracy! - Saving Model\n[4 1 1 1 3 0 4 4 1 1 4 1 1 1 4 1 1 1 3 1 1 4 1 1 2 1 4 4 4 4 1 0]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 20 loss: 1.2582  validation accuracy: 0.5  0.1813 sec/batch\nBest validation accuracy! - Saving Model\n[2 1 1 1 2 2 2 2 1 1 2 2 1 1 2 1 2 1 2 1 1 2 1 2 2 2 2 2 2 2 1 2]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 30 loss: 0.9866  validation accuracy: 0.5  0.1743 sec/batch\n[2 1 1 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 2 1 1 2 1 1 2 2 2 1 2 2 1 2]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, step 10 loss: 0.7969  validation accuracy: 0.59375  0.3064 sec/batch\nBest validation accuracy! - Saving Model\n[2 1 1 1 2 1 2 2 1 0 1 1 1 1 1 1 1 1 2 1 1 2 1 1 2 1 2 1 2 1 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, step 20 loss: 0.7228  validation accuracy: 0.625  0.2063 sec/batch\nBest validation accuracy! - Saving Model\n[2 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 2 1 2 1 2 1 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, step 30 loss: 0.7920  validation accuracy: 0.53125  0.1795 sec/batch\n[2 1 1 1 2 2 2 2 1 1 2 2 1 1 2 1 1 1 2 2 1 2 1 2 2 2 2 1 2 2 1 2]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, step 10 loss: 0.7502  validation accuracy: 0.5625  0.2111 sec/batch\n[2 1 1 1 2 2 2 2 1 1 2 2 1 1 2 1 1 1 2 2 1 2 1 2 2 2 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, step 20 loss: 0.8479  validation accuracy: 0.5625  0.1720 sec/batch\n[2 1 1 1 2 2 2 2 1 1 2 2 1 1 2 1 1 1 2 2 1 2 1 2 2 2 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, step 30 loss: 0.7431  validation accuracy: 0.625  0.1865 sec/batch\n[2 1 1 1 2 2 2 2 1 1 2 2 1 1 2 1 1 1 2 2 1 2 1 2 2 1 2 1 2 1 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, step 10 loss: 0.8415  validation accuracy: 0.5  0.1943 sec/batch\n[2 0 1 0 2 2 2 2 1 0 2 2 0 0 2 1 0 1 2 2 0 2 0 2 2 2 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, step 20 loss: 1.0323  validation accuracy: 0.71875  0.1794 sec/batch\nBest validation accuracy! - Saving Model\n[2 1 1 0 2 2 2 2 1 1 2 2 0 1 1 1 1 1 2 2 1 2 1 1 2 1 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, step 30 loss: 0.8829  validation accuracy: 0.6875  0.1775 sec/batch\n[2 1 1 1 2 2 2 2 1 1 2 1 1 1 1 1 1 1 2 2 1 2 1 1 3 1 2 1 2 1 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, step 10 loss: 0.8396  validation accuracy: 0.65625  0.1735 sec/batch\n[2 1 1 0 2 2 2 2 1 0 2 2 0 0 1 1 0 1 2 2 1 2 1 2 2 1 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, step 20 loss: 0.6839  validation accuracy: 0.6875  0.1931 sec/batch\n[2 1 1 0 2 2 2 2 1 1 2 2 0 0 1 1 1 1 2 2 1 2 0 2 2 1 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, step 30 loss: 0.5486  validation accuracy: 0.75  0.1745 sec/batch\nBest validation accuracy! - Saving Model\n[2 1 1 0 2 2 2 2 1 1 2 1 0 0 1 1 1 1 2 2 1 2 1 2 2 1 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, step 10 loss: 0.5566  validation accuracy: 0.71875  0.1755 sec/batch\n[2 1 1 0 2 2 2 2 1 1 2 1 0 0 2 1 1 1 2 2 1 2 1 2 2 1 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, step 20 loss: 0.6026  validation accuracy: 0.78125  0.1725 sec/batch\nBest validation accuracy! - Saving Model\n[2 1 1 0 2 2 2 2 1 1 2 1 0 0 1 1 1 1 2 2 1 1 0 1 3 1 2 1 2 1 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, step 30 loss: 0.6879  validation accuracy: 0.78125  0.1811 sec/batch\n[2 1 1 0 2 2 2 2 1 1 2 1 0 0 1 1 1 1 2 2 1 1 1 2 2 1 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, step 10 loss: 0.6050  validation accuracy: 0.65625  0.1833 sec/batch\n[2 1 1 0 2 2 2 2 0 1 2 1 0 0 2 1 1 1 2 2 1 2 1 2 2 1 2 1 2 2 1 0]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, step 20 loss: 0.4346  validation accuracy: 0.78125  0.1733 sec/batch\n[2 1 1 0 2 2 2 2 1 0 2 1 0 0 1 1 1 1 2 2 1 2 1 1 2 1 2 1 2 1 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, step 30 loss: 0.4874  validation accuracy: 0.65625  0.2194 sec/batch\n[2 1 1 0 2 2 2 2 1 0 2 1 0 0 0 1 1 1 2 2 1 2 0 2 2 1 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, step 10 loss: 0.6169  validation accuracy: 0.6875  0.1703 sec/batch\n[2 1 1 0 2 2 2 2 0 0 2 1 0 0 0 1 1 1 2 2 1 1 1 2 2 1 2 0 2 1 1 0]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, step 20 loss: 0.4548  validation accuracy: 0.71875  0.1744 sec/batch\n[2 1 1 0 2 2 2 2 0 1 2 1 0 0 1 1 0 1 2 2 1 1 1 2 3 1 2 1 2 1 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, step 30 loss: 0.4165  validation accuracy: 0.6875  0.1768 sec/batch\n[2 1 1 0 2 2 2 2 1 1 2 1 1 0 1 1 1 1 2 2 1 2 1 2 3 1 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, step 10 loss: 0.4393  validation accuracy: 0.6875  0.1723 sec/batch\n[2 1 1 0 2 2 2 2 1 1 2 1 0 0 1 1 1 1 2 2 1 2 0 2 2 1 2 1 2 2 1 0]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, step 20 loss: 0.3469  validation accuracy: 0.625  0.1758 sec/batch\n[2 1 1 0 2 2 2 2 1 0 2 1 0 0 0 1 0 1 2 2 1 1 1 2 3 1 2 1 2 2 1 0]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, step 30 loss: 0.4279  validation accuracy: 0.6875  0.1822 sec/batch\n[1 1 1 0 2 2 2 2 1 0 2 1 0 0 0 1 1 1 2 2 1 1 1 1 3 1 2 1 2 1 1 0]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, step 10 loss: 0.5123  validation accuracy: 0.65625  0.2112 sec/batch\n[2 1 1 0 2 2 2 2 1 0 2 1 0 0 0 1 0 2 2 2 1 1 0 2 3 1 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, step 20 loss: 0.3319  validation accuracy: 0.71875  0.1926 sec/batch\n[2 1 1 1 2 2 2 2 1 1 2 1 0 0 1 1 1 1 2 2 1 2 1 2 2 1 2 1 2 2 1 1]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, step 30 loss: 0.2391  validation accuracy: 0.6875  0.1732 sec/batch\n[2 1 1 0 2 2 2 2 1 0 2 2 0 0 1 1 0 1 2 2 1 1 1 2 2 1 2 0 2 1 1 0]\n[2 1 1 0 2 2 3 1 1 1 2 1 0 0 1 1 1 2 2 2 1 1 1 1 2 1 2 2 2 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "X_val_short = X_val[:batch_size]\n",
    "y_val_short = y_val[:batch_size]\n",
    "n_epochs = 10\n",
    "\n",
    "print('Training Network...')\n",
    "my_net.train(batch_gen, X_val_short, y_val_short, n_epochs, n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/best_model_rnn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running network predictions\n"
     ]
    }
   ],
   "source": [
    "batch_size = X_val.shape[0]\n",
    "seq_length = X_val.shape[1]\n",
    "embed_size = X_val.shape[2]\n",
    "\n",
    "pred_net = RNN(num_classes, batch_size, seq_length, embed_size=embed_size, cell_type='gru',\n",
    "                 rnn_size=128, num_layers=2, learning_rate=0.005, train_keep_prob=1, sampling=False)\n",
    "preds = pred_net.predict('./model/best_model_rnn', X_val)\n",
    "preds = scores_to_preds(preds, min_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6913285600636436"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.preprocess import quadratic_weighted_kappa\n",
    "quadratic_weighted_kappa(preds[0], y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}