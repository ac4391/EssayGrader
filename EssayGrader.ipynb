{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP:\n",
    "The first half of this notebook may be used to train an MLP. Training for RNN models can be found in the second half of this notebook\n",
    "\n",
    "Note that this notebook requires the use of train_df.pkl and test_df.pkl files. These are generated in the preprocess.ipynb notebook. If you have not run this notebook, you will not have the necessary data to proceed with this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import get_batches, shuffle, train_val_split, preds_to_scores,scores_to_preds, plot_train_loss\n",
    "from src.mlp import MLP\n",
    "from src.rnn import RNN\n",
    "import seaborn as sns\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data. This is the training dataframe saved from the preprocessing notebook.\n",
    "data_path = './data/train_df.pkl'\n",
    "train_df = pd.read_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>rater1_domain1_norm</th>\n",
       "      <th>rater2_domain1_norm</th>\n",
       "      <th>norm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>236</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>387</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>204</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  rater1_domain1  rater2_domain1  domain1_score  \\\n",
       "0         1          1               4               4              8   \n",
       "1         2          1               5               4              9   \n",
       "2         3          1               4               3              7   \n",
       "4         5          1               4               4              8   \n",
       "5         6          1               4               4              8   \n",
       "\n",
       "                                        essays_embed  word_count  min_score  \\\n",
       "0  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         299        2.0   \n",
       "1  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         349        2.0   \n",
       "2  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         236        2.0   \n",
       "4  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         387        2.0   \n",
       "5  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         204        2.0   \n",
       "\n",
       "   max_score  rater1_domain1_norm  rater2_domain1_norm  norm_score  \n",
       "0       12.0                    4                    4           8  \n",
       "1       12.0                    5                    4           9  \n",
       "2       12.0                    4                    3           7  \n",
       "4       12.0                    4                    4           8  \n",
       "5       12.0                    4                    4           8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To further isolate our data, we will only examine essays from a single set\n",
    "# Feel free to experiment with different essay sets!\n",
    "\n",
    "set = 1\n",
    "df = train_df.loc[train_df['essay_set'] == set]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should get a plot here to examine score distribution for this set\n",
    "# How many essays of each score do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to avoid bias toward more common scores, we will limit the number\n",
    "# of essays from each scoring bucket to a set value\n",
    "score_df = None\n",
    "min_score = int(df['min_score'].min())\n",
    "max_score = int(df['max_score'].max())\n",
    "\n",
    "n_max = 100\n",
    "for i in range(min_score,max_score+1):\n",
    "    if score_df is None:\n",
    "        score_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "    else:\n",
    "        temp_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "        score_df = pd.concat([score_df, temp_df])\n",
    "df = score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 training essays, each of shape 426 x 200\n"
     ]
    }
   ],
   "source": [
    "# Extract essay vectors and corresponding scores\n",
    "X = np.array(df['essays_embed'])\n",
    "y = np.array(df['domain1_score'])\n",
    "X = np.stack(X, axis=0)\n",
    "print('There are {} training essays, each of shape {} x {}'.format(X.shape[0], X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These essays are the wrong shape to feed directly into the MLP. Therefore, each essay matrix needs to be flattened into a 1-D vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 training essays, each a vector of length 85200\n"
     ]
    }
   ],
   "source": [
    "X_flatten = np.reshape(X, [X.shape[0], -1])\n",
    "print('There are {} training essays, each a vector of length {}'.format(X_flatten.shape[0], X_flatten.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to shuffle the data and separate it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X_flatten, y)\n",
    "\n",
    "X_train, y_train, X_val, y_val = train_val_split(X, y, train_prop=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to transform the labels to the form that the network will predict. For example, in set 1, the essays are graded on a scale from 2-12, therefore there are 11 classes into which the network will try to classify each essay. However, the network will classify essays into the scale 0-10. Therefore, this step will perform this shift on the labels. If the scoring range already starts at 0, no shift is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shifted from a scale of (2,12) to (0,10)\n",
      "Validation labels shifted from a scale of (4,12) to (2,10)\n"
     ]
    }
   ],
   "source": [
    "if min_score != 0:\n",
    "    y_train_adj = scores_to_preds(y_train, min_score)\n",
    "    print('Training labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_train),max(y_train), min(y_train_adj), max(y_train_adj)))\n",
    "    y_val_adj = scores_to_preds(y_val, min_score)\n",
    "    print('Validation labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_val),max(y_val), min(y_val_adj), max(y_val_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_train_adj = y_train\n",
    "    y_val_adj = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial MLP\n",
    "Here we define an MLP model to train. The parameters below were the initial parameters tested on the dataset. This model learns the training set well, but is unable to generalize to the validation set. You may skip training this model to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "model_name = 'mlp_set1_bad'\n",
    "hidden_dims = [128,64]\n",
    "weight_scale = 1e-2\n",
    "batch_size = 16\n",
    "n_epochs = 20\n",
    "l2_reg = 1e-4\n",
    "keep_prob = 1\n",
    "reg = False\n",
    "lr = 1e-3\n",
    "\n",
    "# Derived Parameters\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type='mlp')\n",
    "\n",
    "mlp_net = MLP(input_dim=input_dim, hidden_dims=hidden_dims, num_classes=num_classes, weight_scale=weight_scale,\\\n",
    "              l2_reg=l2_reg, keep_prob=keep_prob, regression=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, Batch 1 -- Loss: 2.409 Validation accuracy: 0.107\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, Batch 1 -- Loss: 1.740 Validation accuracy: 0.119\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, Batch 1 -- Loss: 1.210 Validation accuracy: 0.452\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 5 8 8 5 5 6 8 6 8 8 5 6 5 8 8 5 5\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, Batch 1 -- Loss: 1.099 Validation accuracy: 0.440\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 6 5 8 6 5 5 6 8 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, Batch 1 -- Loss: 0.714 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, Batch 1 -- Loss: 0.525 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 4 7 7 4 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, Batch 1 -- Loss: 0.333 Validation accuracy: 0.393\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, Batch 1 -- Loss: 0.181 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, Batch 1 -- Loss: 0.108 Validation accuracy: 0.405\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, Batch 1 -- Loss: 0.237 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 6 4 7 6 4 5 6 7 6 6 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, Batch 1 -- Loss: 0.226 Validation accuracy: 0.369\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, Batch 1 -- Loss: 0.289 Validation accuracy: 0.405\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 7 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, Batch 1 -- Loss: 0.313 Validation accuracy: 0.333\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, Batch 1 -- Loss: 0.151 Validation accuracy: 0.333\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 4 7 7 5 5 6 7 6 7 8 6 6 6 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, Batch 1 -- Loss: 0.180 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, Batch 1 -- Loss: 0.233 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, Batch 1 -- Loss: 0.112 Validation accuracy: 0.393\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, Batch 1 -- Loss: 0.102 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, Batch 1 -- Loss: 0.232 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, Batch 1 -- Loss: 0.226 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "Total training time: 34.877\n",
      "Best validation accuracy over the training period was: 0.4523809552192688%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = mlp_net.train(gen=batch_gen, X_val=X_val, y_val=y_val_adj, n_epochs=n_epochs, n_batches=n_batches, lr=lr,\\\n",
    "                                               save_every_n=5, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~ac4391/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ac4391/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_train_loss(train_loss_hist, val_loss_hist, n_batches, model_name)\n",
    "py.iplot(fig, filename='basic-area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your own MLP\n",
    "Clearly the MLP above is able to learn the training set, but is unable to generalize for the validation set. Below is another MLP model definition. The user may change the model name and parameters, or leave the model definition as is. The model will be saved to the 'model/' directory of this project. Parameters such as the following may be defined by the user: learning rate, number of training epochs, l2 regularization, dropout probability, and regression vs classification.\n",
    "\n",
    "After many iterations, we found the following mlp parameters yielded the best results on both the training and validation sets. Note that this model is much larger and requires a GPU to train in a reasonable amount of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "model_name = 'mlp_set'+'{}'.format(set)\n",
    "hidden_dims = [1024,256]\n",
    "weight_scale = 1e-2\n",
    "batch_size = 16\n",
    "n_epochs = 20\n",
    "l2_reg = 1e-4\n",
    "keep_prob = 0.6\n",
    "reg = False\n",
    "lr = 1e-4\n",
    "\n",
    "# Derived Parameters\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type='mlp')\n",
    "\n",
    "mlp_net = MLP(input_dim=input_dim, hidden_dims=hidden_dims, num_classes=num_classes, weight_scale=weight_scale,\\\n",
    "              l2_reg=l2_reg, keep_prob=keep_prob, regression=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, Batch 1 -- Loss: 5.657 Validation accuracy: 0.155\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 5 7 9 7 7 9 8 9 8 8 9 9 8 9 8 8 9 9 8\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, Batch 1 -- Loss: 2.071 Validation accuracy: 0.190\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, Batch 1 -- Loss: 1.735 Validation accuracy: 0.167\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 7 6 7 7 5 7 7 8 8 7 7 8 7 7 7 7 8 5\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, Batch 1 -- Loss: 1.913 Validation accuracy: 0.405\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 7 5 5 8 8 5 5 8 8 8 8 8 5 8 5 8 8 5 6\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, Batch 1 -- Loss: 1.496 Validation accuracy: 0.393\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 8 6 5 8 7 5 5 5 7 6 8 8 5 6 5 8 8 4 5\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, Batch 1 -- Loss: 1.246 Validation accuracy: 0.405\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 6 5 8 7 5 5 6 8 6 8 8 6 6 5 8 8 5 5\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, Batch 1 -- Loss: 1.185 Validation accuracy: 0.369\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 6 5 7 6 4 4 6 7 6 7 7 6 6 5 8 8 4 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, Batch 1 -- Loss: 0.732 Validation accuracy: 0.464\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 4 4 6 7 6 7 8 6 7 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, Batch 1 -- Loss: 0.425 Validation accuracy: 0.393\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 6 5 7 7 5 5 6 7 7 7 8 6 6 5 8 8 4 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, Batch 1 -- Loss: 0.792 Validation accuracy: 0.429\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 8 7 5 5 6 7 6 7 8 6 6 5 8 8 4 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, Batch 1 -- Loss: 0.245 Validation accuracy: 0.452\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 8 5 5 6 7 6 7 8 5 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, Batch 1 -- Loss: 0.320 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 4 7 7 5 4 6 7 6 6 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, Batch 1 -- Loss: 0.448 Validation accuracy: 0.464\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 8 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, Batch 1 -- Loss: 0.583 Validation accuracy: 0.452\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 6 5 7 7 5 5 6 7 6 8 8 6 6 5 8 8 4 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, Batch 1 -- Loss: 0.149 Validation accuracy: 0.405\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 7 7 5 5 6 7 6 7 8 5 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, Batch 1 -- Loss: 0.529 Validation accuracy: 0.440\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 7 7 5 5 6 7 6 7 8 5 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, Batch 1 -- Loss: 0.238 Validation accuracy: 0.440\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 4 7 8 5 5 6 7 6 6 8 5 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, Batch 1 -- Loss: 0.155 Validation accuracy: 0.345\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 4 7 7 5 5 6 7 6 7 7 5 6 5 7 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, Batch 1 -- Loss: 0.113 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 7 6 5 7 7 5 5 6 7 6 7 8 6 6 5 8 8 5 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, Batch 1 -- Loss: 0.180 Validation accuracy: 0.500\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 6 5 7 8 5 5 6 7 6 7 8 6 6 5 8 8 4 4\n",
      "Actual:  6 9 6 5 8 9 4 6 6 8 5 7 9 5 5 6 8 7 4 2\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "Total training time: 334.061\n",
      "Best validation accuracy over the training period was: 0.5%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = mlp_net.train(gen=batch_gen, X_val=X_val, y_val=y_val_adj, n_epochs=n_epochs, n_batches=n_batches, lr=lr,\\\n",
    "                                               save_every_n=5, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~ac4391/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ac4391/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_train_loss(train_loss_hist, val_loss_hist, n_batches, model_name)\n",
    "py.iplot(fig, filename='basic-area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the QWK of the trained model\n",
    "Now we can use essays from the test dataset to obtain a quadratic weighted\n",
    "kappa (QWK) score for the model. This metric is used to quantify how well\n",
    "the model predicted the essay scores relative to random guessing. A value\n",
    "of 0 indicates that the predictions were no better than random guessing,\n",
    "while a value of 1 indicates perfect matching between predictions and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 298 testing essays\n",
      "Testing labels shifted from a scale of (4,12) to (2,10)\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/test_df.pkl'\n",
    "test_df = pd.read_pickle(data_path)\n",
    "df = test_df.loc[test_df['essay_set'] == set]\n",
    "X_test = np.array(df['essays_embed'])\n",
    "y_test = np.array(df['domain1_score'])\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "X_test = np.reshape(X_test, [X_test.shape[0], -1])\n",
    "print('There are {} testing essays'.format(X_test.shape[0]))\n",
    "      \n",
    "if min_score != 0:\n",
    "    y_test_adj = scores_to_preds(y_test, min_score)\n",
    "    print('Testing labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_test),max(y_test), min(y_test_adj), max(y_test_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_test_adj = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/mlp_set1\n"
     ]
    }
   ],
   "source": [
    "preds = mlp_net.predict('./model/'+model_name, X_test)\n",
    "\n",
    "# We need to map predictions from classes in the model to actual scores\n",
    "#preds = preds_to_scores(preds, min_score=min_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quadratic weighted kappa score for set 1 using mlp_set1 is : 0.7019728115547382\n"
     ]
    }
   ],
   "source": [
    "from src.utils import quadratic_weighted_kappa\n",
    "y_test_adj = scores_to_preds(y_test, min_score)\n",
    "k = quadratic_weighted_kappa(y_test_adj, preds, num_classes)\n",
    "\n",
    "print('The quadratic weighted kappa score for set {} using {} is : {}'\\\n",
    "     .format(set, model_name, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN:\n",
    "The second half of this notebook may be used for training an RNN - specifically an LSTM or GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>rater1_domain1_norm</th>\n",
       "      <th>rater2_domain1_norm</th>\n",
       "      <th>norm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>236</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>387</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>204</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  rater1_domain1  rater2_domain1  domain1_score  \\\n",
       "0         1          1               4               4              8   \n",
       "1         2          1               5               4              9   \n",
       "2         3          1               4               3              7   \n",
       "4         5          1               4               4              8   \n",
       "5         6          1               4               4              8   \n",
       "\n",
       "                                        essays_embed  word_count  min_score  \\\n",
       "0  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         299        2.0   \n",
       "1  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         349        2.0   \n",
       "2  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         236        2.0   \n",
       "4  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         387        2.0   \n",
       "5  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         204        2.0   \n",
       "\n",
       "   max_score  rater1_domain1_norm  rater2_domain1_norm  norm_score  \n",
       "0       12.0                    4                    4           8  \n",
       "1       12.0                    5                    4           9  \n",
       "2       12.0                    4                    3           7  \n",
       "4       12.0                    4                    4           8  \n",
       "5       12.0                    4                    4           8  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the data\n",
    "data_path = './data/train_df.pkl'\n",
    "train_df = pd.read_pickle(data_path)\n",
    "\n",
    "# To further isolate our data, we will only examine essays from a single set\n",
    "# Feel free to experiment with different essay sets!\n",
    "set = 1\n",
    "df = train_df.loc[train_df['essay_set'] == set]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to avoid bias toward more common scores, we will limit the number\n",
    "# of essays from each scoring bucket to a set value\n",
    "score_df = None\n",
    "min_score = int(df['min_score'].min())\n",
    "max_score = int(df['max_score'].max())\n",
    "\n",
    "n_max = 100\n",
    "for i in range(min_score,max_score+1):\n",
    "    if score_df is None:\n",
    "        score_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "    else:\n",
    "        temp_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "        score_df = pd.concat([score_df, temp_df])\n",
    "df = score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 training essays, each of shape 426 x 200\n"
     ]
    }
   ],
   "source": [
    "# Extract essay vectors and corresponding scores\n",
    "X = np.array(df['essays_embed'])\n",
    "y = np.array(df['domain1_score'])\n",
    "X = np.stack(X, axis=0)\n",
    "print('There are {} training essays, each of shape {} x {}'.format(X.shape[0], X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to shuffle the data and separate it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)\n",
    "X_train, y_train, X_val, y_val = train_val_split(X, y, train_prop=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to transform the labels to the form that the network will predict. For example, in set 1, the essays are graded on a scale from 2-12, therefore there are 11 classes into which the network will try to classify each essay. However, the network will classify essays into the scale 0-10. Therefore, this step will perform this shift on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shifted from a scale of (2,12) to (0,10)\n",
      "Validation labels shifted from a scale of (4,12) to (2,10)\n"
     ]
    }
   ],
   "source": [
    "if min_score != 0:\n",
    "    y_train_adj = scores_to_preds(y_train, min_score)\n",
    "    print('Training labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_train),max(y_train), min(y_train_adj), max(y_train_adj)))\n",
    "    y_val_adj = scores_to_preds(y_val, min_score)\n",
    "    print('Validation labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_val),max(y_val), min(y_val_adj), max(y_val_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_train_adj = y_train\n",
    "    y_val_adj = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial RNN\n",
    "Here we define an RNN model to train. The parameters below were the initial parameters tested on the dataset. model learns the training and validation set well. It serves as a good baseline from which you can design your own RNN. If you'd like, you may skip training this model to save time and move directly to training your own model with tunable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "batch_size = 32\n",
    "cell_type = 'lstm'\n",
    "rnn_size = 128\n",
    "lr = 1e-3\n",
    "n_epochs = 20\n",
    "keep_prob = 1\n",
    "\n",
    "# Derived Parameters\n",
    "model_name = cell_type+'_set'+'{}'.format(set)\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "seq_length = X_train.shape[1]\n",
    "embed_size = X_train.shape[2]\n",
    "\n",
    "X_val_t = X_val[:batch_size]\n",
    "y_val_t = y_val_adj[:batch_size]\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type=cell_type)\n",
    "\n",
    "rnn_net = RNN(num_classes, batch_size, seq_length, embed_size, cell_type=cell_type,\n",
    "                 rnn_size=rnn_size, learning_rate=lr, train_keep_prob=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, step 5 loss: 2.3854  validation accuracy: 0.21875  0.2845 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 7 7 8 7 8 7 8 7 7 7 7 7 7 7 7 7 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 1, step 10 loss: 2.2875  validation accuracy: 0.0625  0.3172 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 1, step 15 loss: 2.3108  validation accuracy: 0.25  0.3019 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 4 4 8 8 4 8 4 8 4 8 8 4 4 4 4 8 4 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, step 5 loss: 2.0712  validation accuracy: 0.0625  0.2790 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 2, step 10 loss: 1.9734  validation accuracy: 0.0625  0.3092 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 7 8 8 7 8 7 8 7 8 8 7 8 7 7 8 8 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 2, step 15 loss: 1.7454  validation accuracy: 0.25  0.3483 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 4 4 6 6 4 8 4 8 4 6 6 4 4 4 4 6 4 8 7\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, step 5 loss: 1.7095  validation accuracy: 0.3125  0.3025 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 6 6 6 6 8 6 8 6 6 6 6 6 6 6 6 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 3, step 10 loss: 2.1015  validation accuracy: 0.125  0.2999 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 5 8 5 8 5 8 5 8 7 5 5 5 5 5 5 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 3, step 15 loss: 1.6452  validation accuracy: 0.125  0.2910 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 8 8 5 8 5 8 5 8 8 5 5 5 5 8 5 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, step 5 loss: 1.9064  validation accuracy: 0.28125  0.2988 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 4 4 5 8 4 8 4 8 4 7 7 4 4 4 4 7 4 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 4, step 10 loss: 1.6666  validation accuracy: 0.15625  0.3463 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 8 8 7 8 5 8 7 8 8 5 8 5 5 8 8 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 4, step 15 loss: 1.8646  validation accuracy: 0.28125  0.2949 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 7 7 5 8 5 8 5 7 7 5 5 5 5 7 5 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, step 5 loss: 1.3426  validation accuracy: 0.15625  0.3197 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 7 7 8 7 8 7 8 7 8 8 7 7 7 7 8 7 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 5, step 10 loss: 2.5278  validation accuracy: 0.46875  0.3427 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 6 4 8 8 6 8 4 8 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 5, step 15 loss: 1.4981  validation accuracy: 0.34375  0.3158 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 4 4 6 8 6 8 4 8 6 8 6 4 6 4 4 6 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, step 5 loss: 1.3268  validation accuracy: 0.375  0.2842 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 4 4 7 8 6 8 4 8 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 6, step 10 loss: 1.2782  validation accuracy: 0.375  0.2918 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 6 4 8 8 6 8 4 8 6 8 8 5 8 4 4 8 7 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 6, step 15 loss: 1.6666  validation accuracy: 0.46875  0.2919 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 6 4 8 8 6 8 4 8 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, step 5 loss: 1.5284  validation accuracy: 0.53125  0.2899 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 7 7 6 8 4 8 6 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 7, step 10 loss: 1.3499  validation accuracy: 0.5  0.2936 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 6 4 7 8 6 8 4 8 6 7 7 5 7 4 4 7 7 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 7, step 15 loss: 1.2227  validation accuracy: 0.375  0.3005 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 4 4 7 8 6 8 4 8 5 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, step 5 loss: 1.4396  validation accuracy: 0.40625  0.2906 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 8 8 6 8 4 8 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 8, step 10 loss: 1.4384  validation accuracy: 0.46875  0.2947 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 6 4 8 8 6 8 4 8 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 8, step 15 loss: 1.5857  validation accuracy: 0.375  0.2978 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 7 8 6 8 4 8 5 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, step 5 loss: 1.4113  validation accuracy: 0.4375  0.2893 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 8 8 6 8 4 8 6 8 8 5 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 9, step 10 loss: 1.3680  validation accuracy: 0.375  0.2823 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 7 8 6 8 4 8 5 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 9, step 15 loss: 1.4253  validation accuracy: 0.4375  0.2903 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 7 8 6 8 5 8 5 8 7 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, step 5 loss: 1.1259  validation accuracy: 0.4375  0.2807 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 8 8 6 8 4 8 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 10, step 10 loss: 1.5162  validation accuracy: 0.375  0.2876 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 8 8 6 8 4 8 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 10, step 15 loss: 1.3629  validation accuracy: 0.46875  0.2936 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 7 8 6 8 4 8 6 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, step 5 loss: 1.1514  validation accuracy: 0.5  0.2802 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 7 8 6 8 4 8 6 8 7 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 11, step 10 loss: 1.4627  validation accuracy: 0.46875  0.2874 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 7 7 6 8 4 8 6 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 11, step 15 loss: 1.4392  validation accuracy: 0.4375  0.2938 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 7 8 6 8 5 8 6 7 7 5 7 5 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, step 5 loss: 1.2357  validation accuracy: 0.4375  0.2813 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 7 8 6 8 4 8 5 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 12, step 10 loss: 1.1938  validation accuracy: 0.4375  0.2836 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 7 8 6 8 5 8 6 8 8 5 6 5 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 12, step 15 loss: 1.2920  validation accuracy: 0.34375  0.2839 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 1 7 8 6 8 4 8 5 7 7 4 6 0 8 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, step 5 loss: 1.4489  validation accuracy: 0.53125  0.2824 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 1 7 8 6 8 4 8 6 7 7 5 6 4 0 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, step 10 loss: 1.2639  validation accuracy: 0.59375  0.2911 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 2 7 8 6 8 4 8 6 8 7 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 13, step 15 loss: 1.2215  validation accuracy: 0.53125  0.2860 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 2 7 8 6 8 4 8 5 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, step 5 loss: 1.5354  validation accuracy: 0.25  0.2805 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 6 8 6 8 5 8 5 8 8 5 6 5 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 14, step 10 loss: 1.1937  validation accuracy: 0.34375  0.2766 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 8 8 6 8 4 8 6 8 8 5 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 14, step 15 loss: 1.4129  validation accuracy: 0.53125  0.2877 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 7 8 6 8 4 8 6 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, step 5 loss: 1.3583  validation accuracy: 0.46875  0.2837 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 7 7 7 8 4 8 6 7 7 5 7 4 4 7 7 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 15, step 10 loss: 1.2510  validation accuracy: 0.53125  0.2871 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 7 7 6 8 4 8 6 7 7 5 7 4 4 7 7 8 7\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 15, step 15 loss: 1.3172  validation accuracy: 0.40625  0.3071 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 6 8 6 8 4 8 5 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, step 5 loss: 1.4189  validation accuracy: 0.4375  0.2797 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 7 8 6 8 4 8 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 16, step 10 loss: 1.2752  validation accuracy: 0.5  0.2908 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 2 8 8 6 8 4 8 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 16, step 15 loss: 1.3399  validation accuracy: 0.4375  0.2946 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 2 7 8 6 8 4 8 5 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, step 5 loss: 1.4296  validation accuracy: 0.53125  0.2812 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 2 7 8 6 8 5 8 6 8 7 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 17, step 10 loss: 1.2275  validation accuracy: 0.4375  0.2794 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 2 7 8 6 8 4 8 5 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 17, step 15 loss: 1.2709  validation accuracy: 0.46875  0.2952 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 2 7 8 6 8 5 8 6 8 7 5 7 5 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, step 5 loss: 1.3101  validation accuracy: 0.5  0.2817 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 2 7 8 6 8 4 8 5 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 18, step 10 loss: 1.4108  validation accuracy: 0.5  0.2919 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 2 7 8 6 8 4 8 5 8 8 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 18, step 15 loss: 1.4272  validation accuracy: 0.5  0.2887 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 2 7 8 6 8 5 8 6 8 8 5 7 5 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, step 5 loss: 1.2462  validation accuracy: 0.375  0.2790 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 6 7 6 8 4 8 6 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 19, step 10 loss: 1.5030  validation accuracy: 0.5  0.2907 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 0 7 8 6 8 5 8 6 7 7 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 19, step 15 loss: 1.2103  validation accuracy: 0.53125  0.2946 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 2 7 8 6 8 5 8 6 8 7 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, step 5 loss: 1.3150  validation accuracy: 0.4375  0.2875 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 7 8 6 8 4 8 6 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 20, step 10 loss: 1.2707  validation accuracy: 0.5  0.2917 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 0 7 8 6 8 4 8 5 7 7 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 20, step 15 loss: 1.3050  validation accuracy: 0.375  0.2788 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 7 7 6 8 4 8 5 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "Total training time: 105.083\n",
      "Best validation accuracy over the training period was: 0.59375%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = rnn_net.train(batch_gen, X_val_t, y_val_t,\\\n",
    "                                              n_epochs, n_batches, save_every_n=5,\\\n",
    "                                              model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~ac4391/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ac4391/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_train_loss(train_loss_hist, val_loss_hist, n_batches, model_name)\n",
    "py.iplot(fig, filename='basic-area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your own RNN\n",
    "The LSTM above is able to learn the training set and performance on the validation set is comparable. These preliminary results are promising, but changing hyperparameters can yield even better results. Below is another RNN model definition. Again, many parameters can be modified by the user or left alone with the parameters that yielded our best results.The model will be saved to the 'model/' directory of this project. \n",
    "\n",
    "After many iterations, we found the following mlp parameters yielded the best results on both the training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "\n",
    "batch_size = 32\n",
    "cell_type = 'gru'\n",
    "rnn_size = 256\n",
    "lr = 1e-3\n",
    "n_epochs = 20\n",
    "keep_prob = 1\n",
    "\n",
    "# Derived Parameters\n",
    "model_name = cell_type+'_set'+'{}'.format(set)\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "seq_length = X_train.shape[1]\n",
    "embed_size = X_train.shape[2]\n",
    "\n",
    "X_val_t = X_val[:batch_size]\n",
    "y_val_t = y_val_adj[:batch_size]\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type=cell_type)\n",
    "\n",
    "rnn_net = RNN(num_classes, batch_size, seq_length, embed_size, cell_type=cell_type,\n",
    "                 rnn_size=rnn_size, learning_rate=lr, train_keep_prob=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, step 5 loss: 2.3528  validation accuracy: 0.0625  0.4819 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 1, step 10 loss: 2.1626  validation accuracy: 0.1875  0.4786 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 6 6 6 5 8 6 8 6 6 6 6 5 6 6 6 5 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 1, step 15 loss: 2.1062  validation accuracy: 0.34375  0.5088 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 6 6 6 6 8 6 8 6 6 6 6 6 6 6 6 6 8 7\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, step 5 loss: 2.1204  validation accuracy: 0.125  0.4977 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 5 7 5 8 5 8 5 5 5 5 5 5 5 5 5 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 2, step 10 loss: 1.9373  validation accuracy: 0.21875  0.4992 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 4 4 4 8 4 8 4 8 4 8 8 4 4 4 4 8 4 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 2, step 15 loss: 1.7281  validation accuracy: 0.15625  0.4883 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 7 8 5 8 5 8 5 8 8 5 5 5 5 8 5 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, step 5 loss: 1.9400  validation accuracy: 0.28125  0.4921 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 7 7 5 7 5 7 5 7 7 5 5 5 5 7 5 7 7\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 3, step 10 loss: 1.8770  validation accuracy: 0.3125  0.5048 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 4 4 8 8 6 8 4 8 6 8 8 4 7 4 4 8 7 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 3, step 15 loss: 1.5201  validation accuracy: 0.4375  0.5046 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 6 8 6 8 4 8 6 8 8 5 6 4 4 6 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, step 5 loss: 1.6180  validation accuracy: 0.25  0.5031 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 5 6 8 6 8 4 8 6 8 8 4 6 2 8 6 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 4, step 10 loss: 1.6200  validation accuracy: 0.40625  0.4852 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 7 8 6 8 5 8 5 7 7 5 6 5 5 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 4, step 15 loss: 1.3874  validation accuracy: 0.4375  0.5110 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 7 7 6 8 4 8 5 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, step 5 loss: 1.3562  validation accuracy: 0.4375  0.4898 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 6 8 6 8 5 8 6 8 8 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 5, step 10 loss: 1.4826  validation accuracy: 0.53125  0.4966 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 7 8 6 8 4 8 6 8 8 5 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 5, step 15 loss: 1.3530  validation accuracy: 0.375  0.5104 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 4 4 7 7 5 8 4 8 5 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, step 5 loss: 1.3682  validation accuracy: 0.4375  0.4943 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 8 8 6 8 5 8 6 8 8 5 6 5 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 6, step 10 loss: 1.5291  validation accuracy: 0.375  0.4856 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 7 8 6 8 4 8 5 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 6, step 15 loss: 1.5736  validation accuracy: 0.46875  0.4995 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 7 7 6 8 5 8 6 7 7 5 6 5 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, step 5 loss: 1.1856  validation accuracy: 0.5  0.4886 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 7 8 6 8 4 8 6 8 7 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 7, step 10 loss: 1.3623  validation accuracy: 0.53125  0.4853 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 7 8 6 8 4 8 6 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 7, step 15 loss: 1.1862  validation accuracy: 0.3125  0.5042 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 2 8 8 6 8 5 8 6 8 8 5 6 5 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, step 5 loss: 1.1648  validation accuracy: 0.46875  0.4890 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 7 8 6 8 4 8 6 8 8 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 8, step 10 loss: 1.1422  validation accuracy: 0.5  0.5072 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 2 7 7 6 8 4 8 5 7 7 4 6 4 2 7 6 8 7\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 8, step 15 loss: 1.3545  validation accuracy: 0.5625  0.5023 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 2 7 7 6 8 5 8 6 7 7 5 6 5 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, step 5 loss: 1.3586  validation accuracy: 0.46875  0.5027 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 2 7 8 6 8 4 8 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 9, step 10 loss: 1.4189  validation accuracy: 0.375  0.4927 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 4 6 8 6 8 4 8 5 8 7 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 9, step 15 loss: 1.4011  validation accuracy: 0.5625  0.5154 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 2 7 8 6 8 4 8 6 8 7 5 6 4 2 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, step 5 loss: 1.1623  validation accuracy: 0.40625  0.4925 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 0 7 8 7 8 5 8 6 8 7 6 7 4 4 7 7 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 10, step 10 loss: 1.4045  validation accuracy: 0.40625  0.4957 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 4 7 7 5 8 4 8 5 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 10, step 15 loss: 1.1680  validation accuracy: 0.375  0.5115 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 2 8 8 6 8 5 8 6 8 8 5 6 5 5 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, step 5 loss: 1.5642  validation accuracy: 0.3125  0.4989 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 8 8 6 8 4 8 5 8 8 5 6 4 0 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 11, step 10 loss: 1.2814  validation accuracy: 0.46875  0.4917 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 0 8 8 6 8 4 8 6 8 8 5 6 5 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 11, step 15 loss: 0.9446  validation accuracy: 0.5625  0.5062 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 6 7 6 8 4 8 6 7 7 4 6 4 4 7 6 7 7\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, step 5 loss: 1.1558  validation accuracy: 0.53125  0.5068 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 7 7 6 9 5 9 6 7 7 5 6 5 4 7 6 7 7\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 12, step 10 loss: 1.0743  validation accuracy: 0.34375  0.4956 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 7 8 5 8 4 8 5 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 12, step 15 loss: 1.3087  validation accuracy: 0.3125  0.5072 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 0 8 8 7 8 4 8 6 8 8 5 7 4 4 8 7 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, step 5 loss: 1.2318  validation accuracy: 0.34375  0.4878 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 6 8 6 8 4 8 5 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, step 10 loss: 1.1779  validation accuracy: 0.53125  0.4898 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 0 7 8 6 8 5 9 6 7 7 5 6 5 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 13, step 15 loss: 1.3717  validation accuracy: 0.40625  0.5067 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 7 8 6 8 4 8 5 7 7 4 6 3 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, step 5 loss: 1.4607  validation accuracy: 0.5625  0.4833 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 0 7 8 6 8 4 8 6 8 8 5 7 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 14, step 10 loss: 1.3666  validation accuracy: 0.40625  0.5081 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 7 8 6 8 4 8 5 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 14, step 15 loss: 1.4564  validation accuracy: 0.28125  0.5065 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 8 8 6 8 5 8 5 8 8 5 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, step 5 loss: 1.2714  validation accuracy: 0.5  0.5295 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 7 8 6 8 4 9 6 7 7 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 15, step 10 loss: 1.4077  validation accuracy: 0.46875  0.4877 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 6 8 6 8 4 8 6 7 7 5 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 15, step 15 loss: 1.1110  validation accuracy: 0.375  0.4929 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 8 8 6 8 4 8 6 8 8 5 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, step 5 loss: 0.9171  validation accuracy: 0.28125  0.4913 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 8 8 6 8 4 8 5 8 8 5 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 16, step 10 loss: 1.0050  validation accuracy: 0.4375  0.4941 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 7 8 6 8 4 8 6 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 16, step 15 loss: 1.1317  validation accuracy: 0.53125  0.4943 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 7 7 6 8 4 9 6 7 7 4 6 4 4 7 6 8 7\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, step 5 loss: 1.1355  validation accuracy: 0.5  0.4802 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 6 0 7 8 7 8 4 8 6 8 7 4 7 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 17, step 10 loss: 1.1295  validation accuracy: 0.4375  0.5038 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 2 7 8 6 8 4 8 5 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 17, step 15 loss: 1.1231  validation accuracy: 0.40625  0.4916 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 0 8 8 6 8 5 8 6 8 8 5 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, step 5 loss: 1.0590  validation accuracy: 0.4375  0.4880 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 7 8 6 8 4 9 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 18, step 10 loss: 1.2161  validation accuracy: 0.53125  0.4962 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 7 8 6 8 4 8 6 7 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 18, step 15 loss: 1.0355  validation accuracy: 0.5  0.4875 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 2 7 8 6 8 4 8 6 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, step 5 loss: 1.0685  validation accuracy: 0.5  0.4859 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 2 7 8 6 8 4 8 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 19, step 10 loss: 1.2013  validation accuracy: 0.5  0.5033 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 2 7 8 6 8 4 8 6 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 19, step 15 loss: 1.1054  validation accuracy: 0.46875  0.5058 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 2 7 8 7 8 4 9 6 8 7 4 6 4 4 7 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, step 5 loss: 1.1154  validation accuracy: 0.53125  0.6390 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 3 7 8 7 8 5 9 6 7 7 5 6 4 4 7 6 8 7\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 20, step 10 loss: 0.8525  validation accuracy: 0.375  0.4847 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 5 0 8 8 6 8 4 9 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "Epoch 20, step 15 loss: 1.3616  validation accuracy: 0.46875  0.5045 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 6 2 7 8 6 8 4 9 6 8 8 4 6 4 4 8 6 8 8\n",
      "Actual:  5 6 2 7 8 6 9 4 8 4 7 9 4 6 4 2 7 6 7 7\n",
      "\n",
      "Total training time: 189.877\n",
      "Best validation accuracy over the training period was: 0.5625%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = rnn_net.train(batch_gen, X_val_t, y_val_t,\\\n",
    "                                              n_epochs, n_batches, save_every_n=2,\\\n",
    "                                              model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~ac4391/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ac4391/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_train_loss(train_loss_hist, val_loss_hist, n_batches, model_name)\n",
    "py.iplot(fig, filename='basic-area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the QWK of the trained model\n",
    "Now we can use essays from the test dataset to obtain a quadratic weighted\n",
    "kappa (QWK) score for the model. This metric is used to quantify how well\n",
    "the model predicted the essay scores relative to random guessing. A value\n",
    "of 0 indicates that the predictions were no better than random guessing,\n",
    "while a value of 1 indicates perfect matching between predictions and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 298 testing essays\n",
      "Testing labels shifted from a scale of (4,12) to (2,10)\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/test_df.pkl'\n",
    "test_df = pd.read_pickle(data_path)\n",
    "df = test_df.loc[test_df['essay_set'] == set]\n",
    "X_test = np.array(df['essays_embed'])\n",
    "y_test = np.array(df['domain1_score'])\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "\n",
    "print('There are {} testing essays'.format(X_test.shape[0]))\n",
    "      \n",
    "if min_score != 0:\n",
    "    y_test_adj = scores_to_preds(y_test, min_score)\n",
    "    print('Testing labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_test),max(y_test), min(y_test_adj), max(y_test_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_test_adj = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/gru_set1\n",
      "Running network predictions\n"
     ]
    }
   ],
   "source": [
    "batch_size = X_test.shape[0]\n",
    "seq_length = X_test.shape[1]\n",
    "embed_size = X_test.shape[2]\n",
    "\n",
    "pred_net = RNN(num_classes, batch_size, seq_length, embed_size, cell_type=cell_type,\n",
    "                 rnn_size=rnn_size, learning_rate=lr, train_keep_prob=1)\n",
    "preds = pred_net.predict('./model/'+model_name, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quadratic weighted kappa score for set 1 using gru_set1 is : 0.690254346079625\n"
     ]
    }
   ],
   "source": [
    "k = quadratic_weighted_kappa(preds[0], y_test_adj, num_classes)\n",
    "\n",
    "print('The quadratic weighted kappa score for set {} using {} is : {}'\\\n",
    "     .format(set, model_name, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets=['set1','set3','set4','set5','set6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ac4391/5.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First here is the training time for each set for each model\n",
    "MLP_training_time = [170.3, 25.5, 11.7, 66.4, 33.1]\n",
    "LSTM_training_time = [157.0, 35.0, 30.0, 39.1, 52.3]\n",
    "GRU_training_time = [177.3, 31.4, 33.1, 42.1, 55.4]\n",
    "\n",
    "trace1 = go.Bar(x=sets,y=MLP_training_time,name='MLP')\n",
    "trace2 = go.Bar(x=sets,y=LSTM_training_time,name='LSTM')\n",
    "trace3 = go.Bar(x=sets,y=GRU_training_time,name='GRU')\n",
    "\n",
    "data = [trace1, trace2, trace3]\n",
    "\n",
    "layout = go.Layout(barmode='group')\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ac4391/5.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then, here is the kappa value for each set for each model\n",
    "MLP_kappa = [0.725, 0.546, 0.600, 0.626, 0.512]\n",
    "LSTM_kappa = [0.69, 0.579, 0.551, 0.658, 0.688]\n",
    "GRU_kappa = [0.69, 0.506, 0.689, 0.664, 0.736]\n",
    "\n",
    "trace1 = go.Bar(x=sets,y=MLP_kappa,name='MLP')\n",
    "trace2 = go.Bar(x=sets,y=LSTM_kappa,name='LSTM')\n",
    "trace3 = go.Bar(x=sets,y=GRU_kappa,name='GRU')\n",
    "\n",
    "data = [trace1, trace2, trace3]\n",
    "\n",
    "layout = go.Layout(barmode='group')\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
