{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP:\n",
    "The first half of this notebook may be used to train an MLP. Training for RNN models can be found in the second half of this notebook\n",
    "\n",
    "Note that this notebook requires the use of train_df.pkl and test_df.pkl files. These are generated in the preprocess.ipynb notebook. If you have not run this notebook, you will not have the necessary data to proceed with this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import get_batches, shuffle, train_val_split, preds_to_scores,scores_to_preds, plot_train_loss\n",
    "from src.mlp import MLP\n",
    "from src.rnn import RNN\n",
    "import seaborn as sns\n",
    "import plotly.plotly as py\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data. This is the training dataframe saved from the preprocessing notebook.\n",
    "data_path = './data/train_df.pkl'\n",
    "train_df = pd.read_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>rater1_domain1_norm</th>\n",
       "      <th>rater2_domain1_norm</th>\n",
       "      <th>norm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>236</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>387</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>204</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  rater1_domain1  rater2_domain1  domain1_score  \\\n",
       "0         1          1               4               4              8   \n",
       "1         2          1               5               4              9   \n",
       "2         3          1               4               3              7   \n",
       "4         5          1               4               4              8   \n",
       "5         6          1               4               4              8   \n",
       "\n",
       "                                        essays_embed  word_count  min_score  \\\n",
       "0  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         299        2.0   \n",
       "1  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         349        2.0   \n",
       "2  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         236        2.0   \n",
       "4  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         387        2.0   \n",
       "5  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         204        2.0   \n",
       "\n",
       "   max_score  rater1_domain1_norm  rater2_domain1_norm  norm_score  \n",
       "0       12.0                    4                    4           8  \n",
       "1       12.0                    5                    4           9  \n",
       "2       12.0                    4                    3           7  \n",
       "4       12.0                    4                    4           8  \n",
       "5       12.0                    4                    4           8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To further isolate our data, we will only examine essays from a single set\n",
    "# Feel free to experiment with different essay sets!\n",
    "\n",
    "set = 1\n",
    "df = train_df.loc[train_df['essay_set'] == set]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should get a plot here to examine score distribution for this set\n",
    "# How many essays of each score do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to avoid bias toward more common scores, we will limit the number\n",
    "# of essays from each scoring bucket to a set value\n",
    "score_df = None\n",
    "min_score = int(df['min_score'].min())\n",
    "max_score = int(df['max_score'].max())\n",
    "\n",
    "n_max = 100\n",
    "for i in range(min_score,max_score+1):\n",
    "    if score_df is None:\n",
    "        score_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "    else:\n",
    "        temp_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "        score_df = pd.concat([score_df, temp_df])\n",
    "df = score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 training essays, each of shape 426 x 200\n"
     ]
    }
   ],
   "source": [
    "# Extract essay vectors and corresponding scores\n",
    "X = np.array(df['essays_embed'])\n",
    "y = np.array(df['domain1_score'])\n",
    "X = np.stack(X, axis=0)\n",
    "print('There are {} training essays, each of shape {} x {}'.format(X.shape[0], X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These essays are the wrong shape to feed directly into the MLP. Therefore, each essay matrix needs to be flattened into a 1-D vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 training essays, each a vector of length 85200\n"
     ]
    }
   ],
   "source": [
    "X_flatten = np.reshape(X, [X.shape[0], -1])\n",
    "print('There are {} training essays, each a vector of length {}'.format(X_flatten.shape[0], X_flatten.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to shuffle the data and separate it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X_flatten, y)\n",
    "\n",
    "X_train, y_train, X_val, y_val = train_val_split(X, y, train_prop=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to transform the labels to the form that the network will predict. For example, in set 1, the essays are graded on a scale from 2-12, therefore there are 11 classes into which the network will try to classify each essay. However, the network will classify essays into the scale 0-10. Therefore, this step will perform this shift on the labels. If the scoring range already starts at 0, no shift is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shifted from a scale of (2,12) to (0,10)\n",
      "Validation labels shifted from a scale of (4,12) to (2,10)\n"
     ]
    }
   ],
   "source": [
    "if min_score != 0:\n",
    "    y_train_adj = scores_to_preds(y_train, min_score)\n",
    "    print('Training labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_train),max(y_train), min(y_train_adj), max(y_train_adj)))\n",
    "    y_val_adj = scores_to_preds(y_val, min_score)\n",
    "    print('Validation labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_val),max(y_val), min(y_val_adj), max(y_val_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_train_adj = y_train\n",
    "    y_val_adj = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial MLP\n",
    "Here we define an MLP model to train. The parameters below were the initial parameters tested on the dataset. This model learns the training set well, but is unable to generalize to the validation set. You may skip training this model to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "model_name = 'mlp_set1_bad'\n",
    "hidden_dims = [128,64]\n",
    "weight_scale = 1e-2\n",
    "batch_size = 16\n",
    "n_epochs = 20\n",
    "l2_reg = 1e-4\n",
    "keep_prob = 1\n",
    "reg = False\n",
    "lr = 1e-3\n",
    "\n",
    "# Derived Parameters\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type='mlp')\n",
    "\n",
    "mlp_net = MLP(input_dim=input_dim, hidden_dims=hidden_dims, num_classes=num_classes, weight_scale=weight_scale,\\\n",
    "              l2_reg=l2_reg, keep_prob=keep_prob, regression=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, Batch 1 -- Loss: 2.499 Validation accuracy: 0.202\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, Batch 1 -- Loss: 1.747 Validation accuracy: 0.202\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 6 8 8 8 8 6 8 6 8 8 8 8 6 8 8 8\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, Batch 1 -- Loss: 1.467 Validation accuracy: 0.357\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 8 6 8 4 8 8 8 8 4 4 4 7 8 7 7 4 7 4 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, Batch 1 -- Loss: 0.654 Validation accuracy: 0.476\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 8 8 7 4 5 4 6 6 6 6 4 6 5 6\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, Batch 1 -- Loss: 0.533 Validation accuracy: 0.476\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 8 8 8 4 5 4 7 7 7 7 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, Batch 1 -- Loss: 0.307 Validation accuracy: 0.440\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 7 8 7 4 5 4 7 7 7 6 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, Batch 1 -- Loss: 0.124 Validation accuracy: 0.452\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 7 8 7 4 5 4 7 7 7 7 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, Batch 1 -- Loss: 0.252 Validation accuracy: 0.488\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 7 8 7 4 5 4 7 7 7 6 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, Batch 1 -- Loss: 0.162 Validation accuracy: 0.476\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 7 8 7 4 5 4 7 7 7 6 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, Batch 1 -- Loss: 0.466 Validation accuracy: 0.464\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 7 8 7 4 5 4 7 7 7 6 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, Batch 1 -- Loss: 0.446 Validation accuracy: 0.488\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 7 8 7 4 5 4 7 7 7 7 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, Batch 1 -- Loss: 0.262 Validation accuracy: 0.500\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 8 5 8 4 8 8 8 7 4 5 4 7 7 6 6 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, Batch 1 -- Loss: 0.276 Validation accuracy: 0.464\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 7 8 7 4 5 4 7 7 6 6 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, Batch 1 -- Loss: 0.309 Validation accuracy: 0.452\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 7 8 7 4 5 4 7 7 7 7 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, Batch 1 -- Loss: 0.370 Validation accuracy: 0.476\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 8 5 7 4 8 8 8 7 4 5 4 7 7 7 6 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, Batch 1 -- Loss: 0.284 Validation accuracy: 0.488\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 8 8 7 4 5 4 7 7 6 6 4 8 5 6\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, Batch 1 -- Loss: 0.257 Validation accuracy: 0.488\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 8 8 7 5 5 4 7 7 7 6 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, Batch 1 -- Loss: 0.172 Validation accuracy: 0.452\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 8 8 7 4 5 4 7 7 7 6 4 8 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, Batch 1 -- Loss: 0.160 Validation accuracy: 0.476\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 7 8 7 4 5 4 7 7 7 6 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, Batch 1 -- Loss: 0.164 Validation accuracy: 0.476\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 8 8 7 4 5 4 7 7 7 6 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "Total training time: 19.545\n",
      "Best validation accuracy over the training period was: 0.5%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = mlp_net.train(gen=batch_gen, X_val=X_val, y_val=y_val_adj, n_epochs=n_epochs, n_batches=n_batches, lr=lr,\\\n",
    "                                               save_every_n=5, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~ac4391/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/miniconda3/envs/EssayGrader_env/lib/python3.6/site-packages/IPython/core/display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ac4391/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_train_loss(train_loss_hist, val_loss_hist, n_batches, model_name)\n",
    "py.iplot(fig, filename='basic-area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your own MLP\n",
    "Clearly the MLP above is able to learn the training set, but is unable to generalize for the validation set. Below is another MLP model definition. The user may change the model name and parameters, or leave the model definition as is. The model will be saved to the 'model/' directory of this project. Parameters such as the following may be defined by the user: learning rate, number of training epochs, l2 regularization, dropout probability, and regression vs classification.\n",
    "\n",
    "After many iterations, we found the following mlp parameters yielded the best results on both the training and validation sets. Note that this model is much larger and requires a GPU to train in a reasonable amount of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "model_name = 'mlp_set'+'{}'.format(set)\n",
    "hidden_dims = [1024,256]\n",
    "weight_scale = 1e-2\n",
    "batch_size = 16\n",
    "n_epochs = 20\n",
    "l2_reg = 1e-4\n",
    "keep_prob = 0.6\n",
    "reg = False\n",
    "lr = 1e-4\n",
    "\n",
    "# Derived Parameters\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type='mlp')\n",
    "\n",
    "mlp_net = MLP(input_dim=input_dim, hidden_dims=hidden_dims, num_classes=num_classes, weight_scale=weight_scale,\\\n",
    "              l2_reg=l2_reg, keep_prob=keep_prob, regression=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, Batch 1 -- Loss: 6.132 Validation accuracy: 0.143\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 6 2 8 7 6 6 6 2 2 6 8 8 6 6 6 2 8\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, Batch 1 -- Loss: 1.996 Validation accuracy: 0.143\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 8 7 9 7 9 7 7 8 9 9 7 8 8 8 5 6 7 7 9\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, Batch 1 -- Loss: 1.998 Validation accuracy: 0.214\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 7 7 7 7 7 7 5 4 5 5 8 7 8 7 8 7 7 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, Batch 1 -- Loss: 1.892 Validation accuracy: 0.357\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 6 8 4 8 8 8 8 5 5 5 8 8 8 7 5 8 4 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, Batch 1 -- Loss: 1.805 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 5 8 8 7 7 5 5 5 7 8 7 7 5 8 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, Batch 1 -- Loss: 0.767 Validation accuracy: 0.429\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 8 5 8 5 8 7 7 7 5 5 5 7 7 7 7 4 6 5 8\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, Batch 1 -- Loss: 0.908 Validation accuracy: 0.440\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 6 8 4 8 8 8 8 5 5 4 6 6 6 6 4 6 4 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, Batch 1 -- Loss: 0.821 Validation accuracy: 0.476\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 7 8 7 4 5 4 7 7 6 6 4 7 5 6\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, Batch 1 -- Loss: 0.605 Validation accuracy: 0.488\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 7 8 7 4 5 4 7 7 7 6 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, Batch 1 -- Loss: 0.221 Validation accuracy: 0.500\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 7 8 7 5 5 4 7 6 7 6 4 6 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, Batch 1 -- Loss: 0.343 Validation accuracy: 0.512\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 8 8 8 5 5 4 6 7 7 6 4 6 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, Batch 1 -- Loss: 0.423 Validation accuracy: 0.429\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 8 8 8 4 5 4 7 7 7 6 4 7 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, Batch 1 -- Loss: 0.597 Validation accuracy: 0.476\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 7 8 7 4 5 4 7 6 6 6 4 6 5 8\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, Batch 1 -- Loss: 0.408 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 8 8 8 5 5 4 7 8 7 5 4 8 5 7\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, Batch 1 -- Loss: 0.293 Validation accuracy: 0.452\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 8 8 8 5 5 4 7 7 7 6 4 6 5 6\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, Batch 1 -- Loss: 0.279 Validation accuracy: 0.405\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 7 8 8 5 5 4 7 8 7 6 4 6 5 6\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, Batch 1 -- Loss: 0.398 Validation accuracy: 0.440\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 7 4 8 8 8 7 5 5 4 7 7 7 7 4 7 5 6\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, Batch 1 -- Loss: 0.412 Validation accuracy: 0.524\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 8 8 7 4 5 4 7 7 7 6 4 7 5 6\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, Batch 1 -- Loss: 0.112 Validation accuracy: 0.440\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 6 8 4 8 8 8 8 4 5 4 6 6 7 7 4 7 5 6\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, Batch 1 -- Loss: 0.112 Validation accuracy: 0.476\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 8 4 8 8 8 7 5 5 4 7 7 7 5 4 7 5 6\n",
      "Actual:  6 8 5 8 2 7 6 10 7 4 6 4 7 7 5 7 4 6 5 7\n",
      "\n",
      "Total training time: 143.075\n",
      "Best validation accuracy over the training period was: 0.523809552192688%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = mlp_net.train(gen=batch_gen, X_val=X_val, y_val=y_val_adj, n_epochs=n_epochs, n_batches=n_batches, lr=lr,\\\n",
    "                                               save_every_n=5, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~ac4391/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ac4391/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_train_loss(train_loss_hist, val_loss_hist, n_batches, model_name)\n",
    "py.iplot(fig, filename='basic-area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the QWK of the trained model\n",
    "Now we can use essays from the test dataset to obtain a quadratic weighted\n",
    "kappa (QWK) score for the model. This metric is used to quantify how well\n",
    "the model predicted the essay scores relative to random guessing. A value\n",
    "of 0 indicates that the predictions were no better than random guessing,\n",
    "while a value of 1 indicates perfect matching between predictions and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 298 testing essays\n",
      "Testing labels shifted from a scale of (4,12) to (2,10)\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/test_df.pkl'\n",
    "test_df = pd.read_pickle(data_path)\n",
    "df = test_df.loc[test_df['essay_set'] == set]\n",
    "X_test = np.array(df['essays_embed'])\n",
    "y_test = np.array(df['domain1_score'])\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "X_test = np.reshape(X_test, [X_test.shape[0], -1])\n",
    "print('There are {} testing essays'.format(X_test.shape[0]))\n",
    "      \n",
    "if min_score != 0:\n",
    "    y_test_adj = scores_to_preds(y_test, min_score)\n",
    "    print('Testing labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_test),max(y_test), min(y_test_adj), max(y_test_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_test_adj = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/mlp_set1\n"
     ]
    }
   ],
   "source": [
    "preds = mlp_net.predict('./model/'+model_name, X_test)\n",
    "\n",
    "# We need to map predictions from classes in the model to actual scores\n",
    "#preds = preds_to_scores(preds, min_score=min_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quadratic weighted kappa score for set 1 using mlp_set1 is : 0.7055854051347291\n"
     ]
    }
   ],
   "source": [
    "from src.utils import quadratic_weighted_kappa\n",
    "y_test_adj = scores_to_preds(y_test, min_score)\n",
    "k = quadratic_weighted_kappa(y_test_adj, preds, num_classes)\n",
    "\n",
    "print('The quadratic weighted kappa score for set {} using {} is : {}'\\\n",
    "     .format(set, model_name, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN:\n",
    "The second half of this notebook may be used for training an RNN - specifically an LSTM or GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>rater1_domain1_norm</th>\n",
       "      <th>rater2_domain1_norm</th>\n",
       "      <th>norm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>236</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>387</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>204</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  rater1_domain1  rater2_domain1  domain1_score  \\\n",
       "0         1          1               4               4              8   \n",
       "1         2          1               5               4              9   \n",
       "2         3          1               4               3              7   \n",
       "4         5          1               4               4              8   \n",
       "5         6          1               4               4              8   \n",
       "\n",
       "                                        essays_embed  word_count  min_score  \\\n",
       "0  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         299        2.0   \n",
       "1  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         349        2.0   \n",
       "2  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         236        2.0   \n",
       "4  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         387        2.0   \n",
       "5  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         204        2.0   \n",
       "\n",
       "   max_score  rater1_domain1_norm  rater2_domain1_norm  norm_score  \n",
       "0       12.0                    4                    4           8  \n",
       "1       12.0                    5                    4           9  \n",
       "2       12.0                    4                    3           7  \n",
       "4       12.0                    4                    4           8  \n",
       "5       12.0                    4                    4           8  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the data\n",
    "data_path = './data/train_df.pkl'\n",
    "train_df = pd.read_pickle(data_path)\n",
    "\n",
    "# To further isolate our data, we will only examine essays from a single set\n",
    "# Feel free to experiment with different essay sets!\n",
    "set = 1\n",
    "df = train_df.loc[train_df['essay_set'] == set]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to avoid bias toward more common scores, we will limit the number\n",
    "# of essays from each scoring bucket to a set value\n",
    "score_df = None\n",
    "min_score = int(df['min_score'].min())\n",
    "max_score = int(df['max_score'].max())\n",
    "\n",
    "n_max = 100\n",
    "for i in range(min_score,max_score+1):\n",
    "    if score_df is None:\n",
    "        score_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "    else:\n",
    "        temp_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "        score_df = pd.concat([score_df, temp_df])\n",
    "df = score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 training essays, each of shape 426 x 200\n"
     ]
    }
   ],
   "source": [
    "# Extract essay vectors and corresponding scores\n",
    "X = np.array(df['essays_embed'])\n",
    "y = np.array(df['domain1_score'])\n",
    "X = np.stack(X, axis=0)\n",
    "print('There are {} training essays, each of shape {} x {}'.format(X.shape[0], X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to shuffle the data and separate it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)\n",
    "X_train, y_train, X_val, y_val = train_val_split(X, y, train_prop=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to transform the labels to the form that the network will predict. For example, in set 1, the essays are graded on a scale from 2-12, therefore there are 11 classes into which the network will try to classify each essay. However, the network will classify essays into the scale 0-10. Therefore, this step will perform this shift on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shifted from a scale of (2,12) to (0,10)\n",
      "Validation labels shifted from a scale of (2,12) to (0,10)\n"
     ]
    }
   ],
   "source": [
    "if min_score != 0:\n",
    "    y_train_adj = scores_to_preds(y_train, min_score)\n",
    "    print('Training labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_train),max(y_train), min(y_train_adj), max(y_train_adj)))\n",
    "    y_val_adj = scores_to_preds(y_val, min_score)\n",
    "    print('Validation labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_val),max(y_val), min(y_val_adj), max(y_val_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_train_adj = y_train\n",
    "    y_val_adj = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial RNN\n",
    "Here we define an RNN model to train. The parameters below were the initial parameters tested on the dataset. model learns the training and validation set well. It serves as a good baseline from which you can design your own RNN. If you'd like, you may skip training this model to save time and move directly to training your own model with tunable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "batch_size = 32\n",
    "cell_type = 'lstm'\n",
    "rnn_size = 128\n",
    "lr = 1e-3\n",
    "n_epochs = 20\n",
    "keep_prob = 1\n",
    "\n",
    "# Derived Parameters\n",
    "model_name = cell_type+'_set'+'{}'.format(set)\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "seq_length = X_train.shape[1]\n",
    "embed_size = X_train.shape[2]\n",
    "\n",
    "X_val_t = X_val[:batch_size]\n",
    "y_val_t = y_val_adj[:batch_size]\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type=cell_type)\n",
    "\n",
    "rnn_net = RNN(num_classes, batch_size, seq_length, embed_size, cell_type=cell_type,\n",
    "                 rnn_size=rnn_size, learning_rate=lr, train_keep_prob=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, step 5 loss: 2.3688  validation accuracy: 0.40625  0.4050 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 5 5 8 5 5 5 8 5 8 5 5 5 5 5 5 8 5\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 1, step 10 loss: 2.3755  validation accuracy: 0.1875  0.4160 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 1, step 15 loss: 2.1035  validation accuracy: 0.40625  0.4128 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 5 5 8 5 5 5 8 5 8 5 5 5 5 5 5 8 5\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, step 5 loss: 2.2533  validation accuracy: 0.40625  0.4122 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 5 5 8 5 5 5 8 5 8 5 5 5 5 5 5 8 5\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 2, step 10 loss: 1.9323  validation accuracy: 0.1875  0.4171 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 2, step 15 loss: 1.8645  validation accuracy: 0.375  0.4120 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 5 5 5 5 5 5 8 5 8 5 5 5 5 5 5 8 5\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, step 5 loss: 1.6677  validation accuracy: 0.25  0.4102 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 6 6 6 8 6 8 6 8 6 8 6 6 6 6 7 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 3, step 10 loss: 2.4200  validation accuracy: 0.1875  0.4131 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 3, step 15 loss: 1.8137  validation accuracy: 0.15625  0.3971 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 6 6 6 10 6 6 6 8 6 10 6 6 6 6 6 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, step 5 loss: 1.9506  validation accuracy: 0.15625  0.4094 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 6 6 6 6 6 6 6 7 6 6 6 6 6 6 6 6 7 6\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 4, step 10 loss: 1.8242  validation accuracy: 0.3125  0.4093 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 5 5 6 5 5 5 7 5 6 5 5 5 5 5 5 7 5\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 4, step 15 loss: 1.9651  validation accuracy: 0.1875  0.4126 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 6 4 4 4 7 4 6 4 7 4 7 4 4 4 4 6 4 7 6\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, step 5 loss: 2.0011  validation accuracy: 0.3125  0.3933 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 5 5 5 8 5 6 5 8 6 8 5 6 6 5 6 6 7 6\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 5, step 10 loss: 1.9058  validation accuracy: 0.46875  0.3965 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 8 5 5 5 8 5 8 5 8 6 8 5 5 5 5 8 5 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 5, step 15 loss: 1.6428  validation accuracy: 0.3125  0.3893 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 8 4 4 4 8 4 8 4 8 6 8 4 4 4 4 8 4 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, step 5 loss: 1.6874  validation accuracy: 0.3125  0.4060 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 4 4 4 8 4 8 4 8 8 8 4 8 8 4 8 8 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 6, step 10 loss: 1.5146  validation accuracy: 0.375  0.4057 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 7 4 4 4 7 4 7 4 7 5 7 4 4 4 4 7 4 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 6, step 15 loss: 1.8080  validation accuracy: 0.375  0.4060 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 7 4 4 4 7 4 7 4 7 4 7 4 4 4 4 7 4 7 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, step 5 loss: 1.4108  validation accuracy: 0.375  0.4039 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 8 4 4 4 8 4 7 4 8 5 8 4 4 4 4 7 4 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 7, step 10 loss: 1.7584  validation accuracy: 0.46875  0.4053 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 8 5 5 5 8 5 7 5 8 5 8 5 5 5 5 6 5 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 7, step 15 loss: 1.8071  validation accuracy: 0.46875  0.3967 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 8 5 5 5 8 5 8 5 8 5 8 5 5 5 5 6 5 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, step 5 loss: 1.3759  validation accuracy: 0.46875  0.4020 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 8 5 5 5 8 5 8 5 8 6 8 5 5 5 5 8 5 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 8, step 10 loss: 1.5767  validation accuracy: 0.34375  0.3908 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 5 4 4 8 4 8 4 8 8 8 4 6 6 4 8 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 8, step 15 loss: 1.6762  validation accuracy: 0.3125  0.3931 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 4 4 4 8 4 8 4 8 6 8 4 6 5 4 8 4 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, step 5 loss: 1.4474  validation accuracy: 0.34375  0.3988 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 4 4 4 8 4 8 4 8 6 8 4 4 4 4 8 4 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 9, step 10 loss: 1.5264  validation accuracy: 0.34375  0.4177 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 4 4 4 8 4 8 4 8 6 8 4 6 6 4 8 5 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 9, step 15 loss: 1.4364  validation accuracy: 0.40625  0.4040 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 7 4 7 4 7 6 7 4 6 6 4 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, step 5 loss: 1.6739  validation accuracy: 0.4375  0.4120 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 7 4 7 4 8 6 8 4 6 6 4 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 10, step 10 loss: 1.3848  validation accuracy: 0.34375  0.4018 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 6 5 4 8 4 8 4 8 6 8 6 6 6 4 8 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 10, step 15 loss: 1.5073  validation accuracy: 0.5  0.4234 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 8 4 7 4 8 6 8 4 6 5 4 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, step 5 loss: 1.4697  validation accuracy: 0.40625  0.3878 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 5 5 8 4 8 4 8 6 8 5 6 6 5 8 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 11, step 10 loss: 1.2404  validation accuracy: 0.46875  0.4070 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 4 4 4 8 4 8 4 8 6 8 4 6 5 4 7 5 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 11, step 15 loss: 1.5096  validation accuracy: 0.5  0.4013 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 4 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, step 5 loss: 1.3906  validation accuracy: 0.4375  0.3899 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 6 4 8 4 7 4 8 6 8 4 6 6 4 7 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 12, step 10 loss: 1.5412  validation accuracy: 0.4375  0.4106 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 8 4 7 4 8 6 8 4 6 6 4 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 12, step 15 loss: 1.3313  validation accuracy: 0.4375  0.4146 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 8 4 7 4 8 6 8 4 6 6 4 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, step 5 loss: 1.3172  validation accuracy: 0.5  0.4014 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 7 4 7 4 8 6 7 4 6 5 4 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 13, step 10 loss: 1.4368  validation accuracy: 0.375  0.3908 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 5 7 4 7 4 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, step 15 loss: 1.2707  validation accuracy: 0.53125  0.4043 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 4 8 6 8 5 6 5 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, step 5 loss: 1.5246  validation accuracy: 0.46875  0.4276 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 5 5 8 4 8 4 8 6 8 5 6 5 5 7 5 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 14, step 10 loss: 1.5516  validation accuracy: 0.375  0.4022 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 5 5 8 4 8 4 8 6 8 5 6 6 5 8 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 14, step 15 loss: 1.5533  validation accuracy: 0.5  0.3929 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 6 5 8 4 7 4 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, step 5 loss: 1.2843  validation accuracy: 0.46875  0.4025 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 4 4 8 4 7 4 8 6 8 4 6 6 4 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 15, step 10 loss: 1.2373  validation accuracy: 0.34375  0.3945 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 6 6 8 4 7 4 8 6 8 6 6 6 6 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 15, step 15 loss: 1.4542  validation accuracy: 0.4375  0.3933 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 8 4 7 4 8 6 8 4 6 5 4 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, step 5 loss: 1.4609  validation accuracy: 0.53125  0.4089 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 4 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 16, step 10 loss: 1.2310  validation accuracy: 0.46875  0.3934 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 4 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 16, step 15 loss: 1.2752  validation accuracy: 0.5  0.3909 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 4 8 4 7 4 8 6 8 5 6 5 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, step 5 loss: 1.1000  validation accuracy: 0.5  0.3861 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 4 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 17, step 10 loss: 1.1595  validation accuracy: 0.4375  0.3934 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 4 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 17, step 15 loss: 1.2184  validation accuracy: 0.46875  0.4174 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 4 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, step 5 loss: 1.2892  validation accuracy: 0.40625  0.4049 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 5 8 5 7 4 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 18, step 10 loss: 1.2586  validation accuracy: 0.46875  0.4081 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 8 4 7 4 8 6 8 4 6 5 4 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 18, step 15 loss: 1.3073  validation accuracy: 0.40625  0.4140 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 8 4 7 4 8 6 8 4 6 6 4 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, step 5 loss: 1.2904  validation accuracy: 0.4375  0.3912 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 6 5 8 4 7 4 8 6 8 6 6 6 5 7 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 19, step 10 loss: 1.2700  validation accuracy: 0.4375  0.3964 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 8 0 7 0 8 6 8 4 6 5 4 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 19, step 15 loss: 0.9976  validation accuracy: 0.46875  0.4045 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 4 8 6 8 5 6 6 5 6 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, step 5 loss: 1.3368  validation accuracy: 0.4375  0.3949 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 7 4 8 6 7 5 6 6 5 6 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 20, step 10 loss: 1.2341  validation accuracy: 0.46875  0.4024 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 7 4 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 20, step 15 loss: 1.2616  validation accuracy: 0.53125  0.4070 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 4 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "Total training time: 150.400\n",
      "Best validation accuracy over the training period was: 0.53125%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = rnn_net.train(batch_gen, X_val_t, y_val_t,\\\n",
    "                                              n_epochs, n_batches, save_every_n=5,\\\n",
    "                                              model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~ac4391/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ac4391/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_train_loss(train_loss_hist, val_loss_hist, n_batches, model_name)\n",
    "py.iplot(fig, filename='basic-area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your own RNN\n",
    "The LSTM above is able to learn the training set and performance on the validation set is comparable. These preliminary results are promising, but changing hyperparameters can yield even better results. Below is another RNN model definition. Again, many parameters can be modified by the user or left alone with the parameters that yielded our best results.The model will be saved to the 'model/' directory of this project. \n",
    "\n",
    "After many iterations, we found the following mlp parameters yielded the best results on both the training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "\n",
    "batch_size = 32\n",
    "cell_type = 'gru'\n",
    "rnn_size = 256\n",
    "lr = 1e-3\n",
    "n_epochs = 20\n",
    "keep_prob = 1\n",
    "\n",
    "# Derived Parameters\n",
    "model_name = cell_type+'_set'+'{}'.format(set)\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "seq_length = X_train.shape[1]\n",
    "embed_size = X_train.shape[2]\n",
    "\n",
    "X_val_t = X_val[:batch_size]\n",
    "y_val_t = y_val_adj[:batch_size]\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type=cell_type)\n",
    "\n",
    "rnn_net = RNN(num_classes, batch_size, seq_length, embed_size, cell_type=cell_type,\n",
    "                 rnn_size=rnn_size, learning_rate=lr, train_keep_prob=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, step 5 loss: 2.2509  validation accuracy: 0.1875  0.4658 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 1, step 10 loss: 2.1954  validation accuracy: 0.375  0.4673 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 7 4 4 4 7 4 7 4 7 4 7 4 4 4 4 7 4 7 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 1, step 15 loss: 2.2256  validation accuracy: 0.375  0.4617 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 7 4 4 4 7 4 7 4 8 4 7 4 4 4 4 7 4 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, step 5 loss: 1.8898  validation accuracy: 0.1875  0.4495 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 2, step 10 loss: 1.7313  validation accuracy: 0.21875  0.4515 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 6 6 6 8 6 8 6 8 6 8 6 6 6 6 8 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 2, step 15 loss: 1.6397  validation accuracy: 0.375  0.4471 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 7 4 7 4 7 6 7 4 6 6 4 6 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, step 5 loss: 1.3452  validation accuracy: 0.40625  0.4531 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 7 1 7 7 7 5 6 6 5 7 6 9 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 3, step 10 loss: 1.7026  validation accuracy: 0.375  0.4672 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 5 5 8 4 8 4 8 6 8 5 6 6 5 8 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 3, step 15 loss: 1.7668  validation accuracy: 0.34375  0.4593 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 5 4 8 4 8 1 8 6 8 5 6 6 4 6 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, step 5 loss: 1.5641  validation accuracy: 0.5625  0.4571 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 7 5 5 4 8 4 7 4 8 6 8 5 5 5 4 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 4, step 10 loss: 1.3674  validation accuracy: 0.59375  0.4476 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 5 5 5 7 4 7 4 7 7 7 5 6 5 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 4, step 15 loss: 1.3774  validation accuracy: 0.4375  0.4840 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 7 4 8 6 7 5 6 6 5 6 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, step 5 loss: 1.2776  validation accuracy: 0.28125  0.6425 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 6 6 4 8 4 8 4 8 6 8 6 6 6 4 8 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 5, step 10 loss: 1.4326  validation accuracy: 0.25  0.5507 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 6 6 6 8 4 8 4 8 6 8 6 6 6 6 8 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 5, step 15 loss: 1.5193  validation accuracy: 0.65625  0.6632 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 7 5 5 5 8 4 7 4 8 5 8 5 5 5 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, step 5 loss: 1.3213  validation accuracy: 0.625  0.4760 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 7 4 7 6 7 5 6 5 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 6, step 10 loss: 1.1723  validation accuracy: 0.53125  0.5779 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 7 3 8 6 8 5 6 5 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 6, step 15 loss: 1.0870  validation accuracy: 0.28125  0.5858 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 6 6 5 8 4 8 4 8 6 8 6 6 6 6 6 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, step 5 loss: 1.5265  validation accuracy: 0.375  0.6912 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 8 4 7 4 8 6 8 4 6 4 4 6 4 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 7, step 10 loss: 1.3138  validation accuracy: 0.53125  0.4730 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 2 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 7, step 15 loss: 1.3853  validation accuracy: 0.53125  0.4701 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 2 8 6 8 5 6 6 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, step 5 loss: 1.5104  validation accuracy: 0.46875  0.5001 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 4 8 6 8 5 6 5 5 6 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 8, step 10 loss: 1.4588  validation accuracy: 0.40625  0.4919 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 4 4 4 8 4 8 2 8 6 8 4 6 6 4 7 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 8, step 15 loss: 1.3899  validation accuracy: 0.46875  0.4964 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 5 5 4 8 4 6 2 8 6 8 5 6 5 4 6 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, step 5 loss: 1.3128  validation accuracy: 0.40625  0.4781 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 5 7 4 8 6 8 5 6 6 5 6 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 9, step 10 loss: 1.2818  validation accuracy: 0.46875  0.5091 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 4 8 4 7 0 8 6 8 5 6 6 4 7 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 9, step 15 loss: 1.2910  validation accuracy: 0.5  0.4884 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 4 8 4 7 0 8 6 8 5 6 6 4 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, step 5 loss: 1.3946  validation accuracy: 0.53125  0.4732 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 7 4 8 6 7 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 10, step 10 loss: 1.3318  validation accuracy: 0.53125  0.4856 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 8 4 7 0 8 6 8 4 5 5 4 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 10, step 15 loss: 1.4605  validation accuracy: 0.40625  0.4887 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 5 5 8 4 8 4 8 6 8 5 6 6 5 8 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, step 5 loss: 1.2102  validation accuracy: 0.46875  0.4838 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 4 8 4 7 0 8 6 8 5 6 5 5 6 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 11, step 10 loss: 1.2119  validation accuracy: 0.4375  0.5006 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 5 7 4 8 6 8 5 6 6 5 7 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 11, step 15 loss: 1.0528  validation accuracy: 0.4375  0.4661 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 7 4 7 2 8 6 7 4 6 6 4 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, step 5 loss: 1.2822  validation accuracy: 0.5  0.4918 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 4 8 4 7 2 8 6 8 5 6 6 4 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 12, step 10 loss: 1.3434  validation accuracy: 0.375  0.5073 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 5 5 4 8 4 8 2 8 6 8 5 6 6 5 6 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 12, step 15 loss: 1.4973  validation accuracy: 0.53125  0.4837 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 4 8 6 8 5 6 5 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, step 5 loss: 1.0159  validation accuracy: 0.5625  0.4981 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 4 7 4 7 0 8 6 7 5 6 5 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, step 10 loss: 1.3675  validation accuracy: 0.53125  0.5126 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 3 8 6 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 13, step 15 loss: 1.2480  validation accuracy: 0.40625  0.4711 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 8 3 8 6 8 5 6 6 5 6 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, step 5 loss: 1.1263  validation accuracy: 0.3125  0.4602 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 5 5 4 8 4 6 0 8 6 8 5 6 6 5 6 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 14, step 10 loss: 1.2460  validation accuracy: 0.5  0.4528 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 7 4 8 6 7 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 14, step 15 loss: 1.2397  validation accuracy: 0.59375  0.4671 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 7 2 8 6 8 5 6 5 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, step 5 loss: 1.1599  validation accuracy: 0.5  0.4530 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 7 2 8 6 8 5 6 6 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 15, step 10 loss: 1.3529  validation accuracy: 0.4375  0.4433 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 7 4 8 6 7 5 6 6 5 6 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 15, step 15 loss: 1.2484  validation accuracy: 0.4375  0.4408 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 5 8 4 8 2 8 6 8 5 6 6 5 7 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, step 5 loss: 1.1310  validation accuracy: 0.375  0.4486 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 8 6 5 5 8 4 8 4 8 6 8 5 6 6 5 8 6 8 8\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 16, step 10 loss: 1.1935  validation accuracy: 0.4375  0.4490 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 4 4 7 4 6 2 8 6 7 4 6 6 4 6 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 16, step 15 loss: 1.2976  validation accuracy: 0.4375  0.4586 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 6 5 5 7 4 7 4 8 6 7 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, step 5 loss: 1.2628  validation accuracy: 0.40625  0.4678 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 8 3 8 7 8 5 6 6 5 7 6 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 17, step 10 loss: 1.3232  validation accuracy: 0.5  0.4548 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 7 2 8 6 7 5 6 6 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 17, step 15 loss: 1.1311  validation accuracy: 0.5  0.4504 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 4 7 4 7 4 8 6 7 5 6 6 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, step 5 loss: 1.0140  validation accuracy: 0.46875  0.4657 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 4 8 4 8 2 8 6 8 5 6 6 4 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 18, step 10 loss: 1.0519  validation accuracy: 0.40625  0.4653 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 4 7 4 8 2 8 6 7 4 6 6 4 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 18, step 15 loss: 0.8515  validation accuracy: 0.4375  0.4623 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 8 4 8 6 7 5 6 6 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, step 5 loss: 1.2128  validation accuracy: 0.46875  0.4572 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 8 4 8 6 7 5 6 6 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 19, step 10 loss: 0.9800  validation accuracy: 0.4375  0.4619 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 4 7 4 8 2 8 6 7 5 6 6 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 19, step 15 loss: 1.2168  validation accuracy: 0.4375  0.4709 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 4 7 4 8 2 8 6 7 5 6 6 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, step 5 loss: 0.8791  validation accuracy: 0.4375  0.4683 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 8 4 8 4 8 6 8 5 6 6 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 20, step 10 loss: 1.0217  validation accuracy: 0.46875  0.4722 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 5 7 4 8 4 8 6 7 5 6 6 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "Epoch 20, step 15 loss: 1.0819  validation accuracy: 0.5  0.4634 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 5 4 7 4 8 2 8 6 7 5 6 6 5 7 5 8 7\n",
      "Actual:  7 7 5 4 5 8 4 7 2 9 8 7 5 5 5 4 7 5 7 8\n",
      "\n",
      "Total training time: 198.208\n",
      "Best validation accuracy over the training period was: 0.65625%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = rnn_net.train(batch_gen, X_val_t, y_val_t,\\\n",
    "                                              n_epochs, n_batches, save_every_n=2,\\\n",
    "                                              model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~ac4391/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ac4391/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_train_loss(train_loss_hist, val_loss_hist, n_batches, model_name)\n",
    "py.iplot(fig, filename='basic-area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the QWK of the trained model\n",
    "Now we can use essays from the test dataset to obtain a quadratic weighted\n",
    "kappa (QWK) score for the model. This metric is used to quantify how well\n",
    "the model predicted the essay scores relative to random guessing. A value\n",
    "of 0 indicates that the predictions were no better than random guessing,\n",
    "while a value of 1 indicates perfect matching between predictions and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 298 testing essays\n",
      "Testing labels shifted from a scale of (4,12) to (2,10)\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/test_df.pkl'\n",
    "test_df = pd.read_pickle(data_path)\n",
    "df = test_df.loc[test_df['essay_set'] == set]\n",
    "X_test = np.array(df['essays_embed'])\n",
    "y_test = np.array(df['domain1_score'])\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "\n",
    "print('There are {} testing essays'.format(X_test.shape[0]))\n",
    "      \n",
    "if min_score != 0:\n",
    "    y_test_adj = scores_to_preds(y_test, min_score)\n",
    "    print('Testing labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_test),max(y_test), min(y_test_adj), max(y_test_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_test_adj = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/gru_set1\n",
      "Running network predictions\n"
     ]
    }
   ],
   "source": [
    "batch_size = X_test.shape[0]\n",
    "seq_length = X_test.shape[1]\n",
    "embed_size = X_test.shape[2]\n",
    "\n",
    "pred_net = RNN(num_classes, batch_size, seq_length, embed_size, cell_type=cell_type,\n",
    "                 rnn_size=rnn_size, learning_rate=lr, train_keep_prob=1)\n",
    "preds = pred_net.predict('./model/'+model_name, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quadratic weighted kappa score for set 1 using gru_set1 is : 0.6958062221753905\n"
     ]
    }
   ],
   "source": [
    "k = quadratic_weighted_kappa(preds[0], y_test_adj, num_classes)\n",
    "\n",
    "print('The quadratic weighted kappa score for set {} using {} is : {}'\\\n",
    "     .format(set, model_name, k))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
