{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP:\n",
    "The first half of this notebook may be used to train an MLP. Training for RNN models can be found in the second half of this notebook\n",
    "\n",
    "Note that this notebook requires the use of train_df.pkl and test_df.pkl files. These are generated in the preprocess.ipynb notebook. If you have not run this notebook, you will not have the necessary data to proceed with this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import get_batches, shuffle, train_val_split, preds_to_scores,scores_to_preds, plot_train_loss\n",
    "from src.mlp import MLP\n",
    "from src.rnn import RNN\n",
    "import seaborn as sns\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data. This is the training dataframe saved from the preprocessing notebook.\n",
    "# If you have not run the preprocessing notebook, go back and do so now.\n",
    "data_path = './data/train_df.pkl'\n",
    "train_df = pd.read_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>rater1_domain1_norm</th>\n",
       "      <th>rater2_domain1_norm</th>\n",
       "      <th>norm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>236</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>387</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>204</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  rater1_domain1  rater2_domain1  domain1_score  \\\n",
       "0         1          1               4               4              8   \n",
       "1         2          1               5               4              9   \n",
       "2         3          1               4               3              7   \n",
       "4         5          1               4               4              8   \n",
       "5         6          1               4               4              8   \n",
       "\n",
       "                                        essays_embed  word_count  min_score  \\\n",
       "0  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         299        2.0   \n",
       "1  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         349        2.0   \n",
       "2  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         236        2.0   \n",
       "4  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         387        2.0   \n",
       "5  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         204        2.0   \n",
       "\n",
       "   max_score  rater1_domain1_norm  rater2_domain1_norm  norm_score  \n",
       "0       12.0                    4                    4           8  \n",
       "1       12.0                    5                    4           9  \n",
       "2       12.0                    4                    3           7  \n",
       "4       12.0                    4                    4           8  \n",
       "5       12.0                    4                    4           8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To further isolate our data, we will only examine essays from a single set\n",
    "# Feel free to experiment with different essay sets by choosing a different value\n",
    "# for the set variable. Sets 1, 3, 4, 5, and 6 are supported!\n",
    "\n",
    "set = 1\n",
    "\n",
    "df = train_df.loc[train_df['essay_set'] == set]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to avoid bias toward more common scores, we will limit the number\n",
    "# of essays from each scoring bucket to a set value\n",
    "score_df = None\n",
    "min_score = int(df['min_score'].min())\n",
    "max_score = int(df['max_score'].max())\n",
    "\n",
    "n_max = 100\n",
    "\n",
    "for i in range(min_score,max_score+1):\n",
    "    if score_df is None:\n",
    "        score_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "    else:\n",
    "        temp_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "        score_df = pd.concat([score_df, temp_df])\n",
    "df = score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 training essays, each of shape 426 x 200\n"
     ]
    }
   ],
   "source": [
    "# Extract essay vectors and corresponding scores\n",
    "X = np.array(df['essays_embed'])\n",
    "y = np.array(df['domain1_score'])\n",
    "X = np.stack(X, axis=0)\n",
    "print('There are {} training essays, each of shape {} x {}'.format(X.shape[0], X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These essays are the wrong shape to feed directly into the MLP. Therefore, each essay matrix needs to be flattened into a 1-D vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 training essays, each a vector of length 85200\n"
     ]
    }
   ],
   "source": [
    "X_flatten = np.reshape(X, [X.shape[0], -1])\n",
    "print('There are {} training essays, each a vector of length {}'.format(X_flatten.shape[0], X_flatten.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to shuffle the data and separate it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X_flatten, y)\n",
    "\n",
    "X_train, y_train, X_val, y_val = train_val_split(X, y, train_prop=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to transform the labels to the form that the network will predict. For example, in set 1, the essays are graded on a scale from 2-12, therefore there are 11 classes into which the network will try to classify each essay. However, the network will classify essays into the scale 0-10. Therefore, this step will perform this shift on the labels. If the scoring range already starts at 0, no shift is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shifted from a scale of (2,12) to (0,10)\n",
      "Validation labels shifted from a scale of (2,12) to (0,10)\n"
     ]
    }
   ],
   "source": [
    "if min_score != 0:\n",
    "    y_train_adj = scores_to_preds(y_train, min_score)\n",
    "    print('Training labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_train),max(y_train), min(y_train_adj), max(y_train_adj)))\n",
    "    y_val_adj = scores_to_preds(y_val, min_score)\n",
    "    print('Validation labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_val),max(y_val), min(y_val_adj), max(y_val_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_train_adj = y_train\n",
    "    y_val_adj = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial MLP\n",
    "Here we define an MLP model to train. The parameters below were the initial parameters tested on the dataset. This model learns the training set well, but is unable to generalize to the validation set. You may skip training this model to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "model_name = 'mlp_set1_bad'\n",
    "hidden_dims = [128,64]\n",
    "weight_scale = 1e-2\n",
    "batch_size = 16\n",
    "n_epochs = 20\n",
    "l2_reg = 1e-4\n",
    "keep_prob = 1\n",
    "reg = False\n",
    "lr = 1e-3\n",
    "\n",
    "# Derived Parameters\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type='mlp')\n",
    "\n",
    "mlp_net = MLP(input_dim=input_dim, hidden_dims=hidden_dims, num_classes=num_classes, weight_scale=weight_scale,\\\n",
    "              l2_reg=l2_reg, keep_prob=keep_prob, regression=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, Batch 1 -- Loss: 2.475 Validation accuracy: 0.119\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, Batch 1 -- Loss: 1.746 Validation accuracy: 0.238\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 4 4 7 4 7 7 7 7 7 7 4 7 7 4 4 7 7 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, Batch 1 -- Loss: 1.934 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 5 4 5 7 8 7 8 8 4 7 5 4 4 8 7 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, Batch 1 -- Loss: 1.229 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 5 5 5 5 7 7 7 7 7 4 7 5 4 5 7 7 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, Batch 1 -- Loss: 0.531 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 5 4 5 7 7 7 8 7 4 7 5 4 5 7 7 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, Batch 1 -- Loss: 0.277 Validation accuracy: 0.393\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 4 5 4 5 7 7 6 7 7 4 7 5 4 4 7 7 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, Batch 1 -- Loss: 0.116 Validation accuracy: 0.333\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 4 5 4 5 7 7 6 7 7 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, Batch 1 -- Loss: 0.213 Validation accuracy: 0.357\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 4 5 4 5 7 7 6 7 7 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, Batch 1 -- Loss: 0.090 Validation accuracy: 0.345\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 4 5 4 5 7 7 6 8 7 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, Batch 1 -- Loss: 0.079 Validation accuracy: 0.321\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 4 5 4 5 7 7 6 8 7 4 7 5 4 4 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, Batch 1 -- Loss: 0.084 Validation accuracy: 0.369\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 4 5 4 5 7 7 6 7 7 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, Batch 1 -- Loss: 0.068 Validation accuracy: 0.357\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 4 5 4 5 7 7 6 8 7 4 7 5 4 4 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, Batch 1 -- Loss: 0.203 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 5 4 5 7 7 6 8 7 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, Batch 1 -- Loss: 0.277 Validation accuracy: 0.393\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 5 4 5 7 7 6 8 7 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, Batch 1 -- Loss: 0.288 Validation accuracy: 0.393\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 5 4 5 7 7 6 8 7 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, Batch 1 -- Loss: 0.275 Validation accuracy: 0.369\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 4 5 4 5 7 7 6 8 7 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, Batch 1 -- Loss: 0.361 Validation accuracy: 0.333\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 4 5 4 5 7 7 6 7 7 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, Batch 1 -- Loss: 0.040 Validation accuracy: 0.405\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 4 5 4 5 7 7 6 8 7 4 7 5 4 4 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, Batch 1 -- Loss: 0.198 Validation accuracy: 0.405\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 4 5 4 5 7 7 6 8 7 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, Batch 1 -- Loss: 0.074 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 4 5 4 5 7 7 7 7 7 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "Total training time: 16.994\n",
      "Best validation accuracy over the training period was: 0.4166666567325592%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = mlp_net.train(gen=batch_gen, X_val=X_val, y_val=y_val_adj, n_epochs=n_epochs, n_batches=n_batches, lr=lr,\\\n",
    "                                               save_every_n=5, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~pmt210/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/miniconda3/envs/EssayGrader_env/lib/python3.6/site-packages/IPython/core/display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pmt210/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_train_loss(train_loss_hist, val_loss_hist, n_batches, model_name)\n",
    "py.iplot(fig, filename='basic-area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your own MLP\n",
    "The MLP above is able to learn the training set, but is unable to generalize for the validation set. Below is another MLP model definition. The user may change the model name and parameters, or leave the model definition as is. The model will be saved to the 'model/' directory of this project. Parameters such as the following may be defined by the user: learning rate, number of training epochs, l2 regularization, dropout probability, and regression vs classification.\n",
    "\n",
    "After many iterations, we found the following mlp parameters yielded the best results on both the training and validation sets. Note that this model is much larger and requires a GPU to train in a reasonable amount of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "model_name = 'mlp_set'+'{}'.format(set)\n",
    "hidden_dims = [1024,256]\n",
    "weight_scale = 1e-2\n",
    "batch_size = 16\n",
    "n_epochs = 20\n",
    "l2_reg = 1e-4\n",
    "keep_prob = 0.6\n",
    "reg = False\n",
    "lr = 1e-4\n",
    "\n",
    "# Derived Parameters\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type='mlp')\n",
    "\n",
    "mlp_net = MLP(input_dim=input_dim, hidden_dims=hidden_dims, num_classes=num_classes, weight_scale=weight_scale,\\\n",
    "              l2_reg=l2_reg, keep_prob=keep_prob, regression=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, Batch 1 -- Loss: 5.514 Validation accuracy: 0.119\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 4 7 2 4 8 8 8 7 8 4 8 8 2 7 0 8 1 2\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, Batch 1 -- Loss: 2.409 Validation accuracy: 0.202\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 7 4 8 7 6 8 8 8 7 7 8 8 8 8 8 8 8\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, Batch 1 -- Loss: 1.730 Validation accuracy: 0.179\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 8 8 8 5 7 5 8 7 7 7 7 5 8 7 5 6 7 7 7\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, Batch 1 -- Loss: 1.732 Validation accuracy: 0.357\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 5 4 5 5 4 7 8 6 8 8 5 8 6 4 5 8 8 5\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, Batch 1 -- Loss: 1.268 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 5 4 4 4 4 6 8 6 8 8 4 6 4 4 4 8 7 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, Batch 1 -- Loss: 1.116 Validation accuracy: 0.369\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 4 5 4 5 7 7 6 8 8 5 7 4 4 4 8 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, Batch 1 -- Loss: 0.878 Validation accuracy: 0.333\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 7 4 4 4 5 4 7 8 6 8 8 4 7 5 4 4 8 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, Batch 1 -- Loss: 0.680 Validation accuracy: 0.393\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 4 5 4 4 7 7 6 7 8 4 6 4 4 4 6 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, Batch 1 -- Loss: 0.764 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 5 5 4 5 7 7 6 7 7 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, Batch 1 -- Loss: 0.206 Validation accuracy: 0.440\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 5 5 5 4 5 7 8 7 7 7 4 6 5 4 5 6 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "Best validation accuracy! - Saving Model\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, Batch 1 -- Loss: 0.300 Validation accuracy: 0.440\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 4 5 4 5 7 8 7 7 8 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, Batch 1 -- Loss: 0.599 Validation accuracy: 0.369\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 7 4 4 5 4 5 8 8 7 7 8 4 7 5 4 5 8 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, Batch 1 -- Loss: 0.429 Validation accuracy: 0.357\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 5 5 4 5 8 7 6 8 8 4 7 5 4 5 8 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, Batch 1 -- Loss: 0.175 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 5 5 4 5 7 8 7 7 8 4 7 5 4 5 7 7 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, Batch 1 -- Loss: 0.221 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 4 5 5 4 5 8 8 6 8 6 4 6 4 4 5 8 7 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, Batch 1 -- Loss: 0.129 Validation accuracy: 0.345\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 4 5 4 5 7 8 7 7 8 4 7 5 4 5 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, Batch 1 -- Loss: 0.494 Validation accuracy: 0.286\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 4 5 4 4 7 7 6 7 8 4 7 5 4 4 8 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, Batch 1 -- Loss: 0.232 Validation accuracy: 0.393\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 6 4 5 5 4 5 7 8 7 8 8 4 7 4 4 4 7 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, Batch 1 -- Loss: 0.111 Validation accuracy: 0.417\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 5 5 4 5 7 7 6 7 7 4 6 5 4 5 8 7 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, Batch 1 -- Loss: 0.112 Validation accuracy: 0.381\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 6 4 5 5 4 5 6 8 6 8 6 4 6 5 4 5 8 6 4\n",
      "Actual:  6 5 4 5 6 4 5 7 8 8 7 10 4 6 6 3 4 6 7 4\n",
      "\n",
      "Total training time: 82.586\n",
      "Best validation accuracy over the training period was: 0.4404761791229248%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = mlp_net.train(gen=batch_gen, X_val=X_val, y_val=y_val_adj, n_epochs=n_epochs, n_batches=n_batches, lr=lr,\\\n",
    "                                               save_every_n=5, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~pmt210/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pmt210/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_train_loss(train_loss_hist, val_loss_hist, n_batches, model_name)\n",
    "py.iplot(fig, filename='basic-area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the QWK of the trained model\n",
    "Now we can use essays from the test dataset to obtain a quadratic weighted\n",
    "kappa (QWK) score for the model. This metric is used to quantify how well\n",
    "the model predicted the essay scores relative to random guessing. A value\n",
    "of 0 indicates that the predictions were no better than random guessing,\n",
    "while a value of 1 indicates perfect matching between predictions and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 298 testing essays\n",
      "Testing labels shifted from a scale of (4,12) to (2,10)\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/test_df.pkl'\n",
    "test_df = pd.read_pickle(data_path)\n",
    "df = test_df.loc[test_df['essay_set'] == set]\n",
    "X_test = np.array(df['essays_embed'])\n",
    "y_test = np.array(df['domain1_score'])\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "X_test = np.reshape(X_test, [X_test.shape[0], -1])\n",
    "print('There are {} testing essays'.format(X_test.shape[0]))\n",
    "      \n",
    "if min_score != 0:\n",
    "    y_test_adj = scores_to_preds(y_test, min_score)\n",
    "    print('Testing labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_test),max(y_test), min(y_test_adj), max(y_test_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_test_adj = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/mlp_set1\n"
     ]
    }
   ],
   "source": [
    "preds = mlp_net.predict('./model/'+model_name, X_test)\n",
    "\n",
    "# We need to map predictions from classes in the model to actual scores\n",
    "#preds = preds_to_scores(preds, min_score=min_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quadratic weighted kappa score for set 1 using mlp_set1 is : 0.7032761357170665\n"
     ]
    }
   ],
   "source": [
    "from src.utils import quadratic_weighted_kappa\n",
    "y_test_adj = scores_to_preds(y_test, min_score)\n",
    "k = quadratic_weighted_kappa(y_test_adj, preds, num_classes)\n",
    "\n",
    "print('The quadratic weighted kappa score for set {} using {} is : {}'\\\n",
    "     .format(set, model_name, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN:\n",
    "The second half of this notebook may be used for training an RNN - specifically an LSTM or GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>essays_embed</th>\n",
       "      <th>word_count</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>rater1_domain1_norm</th>\n",
       "      <th>rater2_domain1_norm</th>\n",
       "      <th>norm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>299</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>236</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>387</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>[[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...</td>\n",
       "      <td>204</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set  rater1_domain1  rater2_domain1  domain1_score  \\\n",
       "0         1          1               4               4              8   \n",
       "1         2          1               5               4              9   \n",
       "2         3          1               4               3              7   \n",
       "4         5          1               4               4              8   \n",
       "5         6          1               4               4              8   \n",
       "\n",
       "                                        essays_embed  word_count  min_score  \\\n",
       "0  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         299        2.0   \n",
       "1  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         349        2.0   \n",
       "2  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         236        2.0   \n",
       "4  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         387        2.0   \n",
       "5  [[0.1285, 0.68849, 0.83504, -0.16483, -0.36831...         204        2.0   \n",
       "\n",
       "   max_score  rater1_domain1_norm  rater2_domain1_norm  norm_score  \n",
       "0       12.0                    4                    4           8  \n",
       "1       12.0                    5                    4           9  \n",
       "2       12.0                    4                    3           7  \n",
       "4       12.0                    4                    4           8  \n",
       "5       12.0                    4                    4           8  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the data\n",
    "data_path = './data/train_df.pkl'\n",
    "train_df = pd.read_pickle(data_path)\n",
    "\n",
    "# To further isolate our data, we will only examine essays from a single set\n",
    "# Feel free to experiment with different essay sets!\n",
    "set = 1\n",
    "df = train_df.loc[train_df['essay_set'] == set]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to avoid bias toward more common scores, we will limit the number\n",
    "# of essays from each scoring bucket to a set value\n",
    "score_df = None\n",
    "min_score = int(df['min_score'].min())\n",
    "max_score = int(df['max_score'].max())\n",
    "\n",
    "n_max = 100\n",
    "for i in range(min_score,max_score+1):\n",
    "    if score_df is None:\n",
    "        score_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "    else:\n",
    "        temp_df = df.loc[df['domain1_score'] == i][:n_max]\n",
    "        score_df = pd.concat([score_df, temp_df])\n",
    "df = score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 566 training essays, each of shape 426 x 200\n"
     ]
    }
   ],
   "source": [
    "# Extract essay vectors and corresponding scores\n",
    "X = np.array(df['essays_embed'])\n",
    "y = np.array(df['domain1_score'])\n",
    "X = np.stack(X, axis=0)\n",
    "print('There are {} training essays, each of shape {} x {}'.format(X.shape[0], X.shape[1], X.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to shuffle the data and separate it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)\n",
    "X_train, y_train, X_val, y_val = train_val_split(X, y, train_prop=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need to transform the labels to the form that the network will predict. For example, in set 1, the essays are graded on a scale from 2-12, therefore there are 11 classes into which the network will try to classify each essay. However, the network will classify essays into the scale 0-10. Therefore, this step will perform this shift on the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shifted from a scale of (2,12) to (0,10)\n",
      "Validation labels shifted from a scale of (2,12) to (0,10)\n"
     ]
    }
   ],
   "source": [
    "if min_score != 0:\n",
    "    y_train_adj = scores_to_preds(y_train, min_score)\n",
    "    print('Training labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_train),max(y_train), min(y_train_adj), max(y_train_adj)))\n",
    "    y_val_adj = scores_to_preds(y_val, min_score)\n",
    "    print('Validation labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_val),max(y_val), min(y_val_adj), max(y_val_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_train_adj = y_train\n",
    "    y_val_adj = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial RNN\n",
    "Here we define an RNN model to train. The parameters below were the initial parameters tested on the dataset. model learns the training and validation set well. It serves as a good baseline from which you can design your own RNN. If you'd like, you may skip training this model to save time and move directly to training your own model with tunable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "batch_size = 32\n",
    "cell_type = 'lstm'\n",
    "rnn_size = 128\n",
    "lr = 1e-3\n",
    "n_epochs = 20\n",
    "keep_prob = 1\n",
    "\n",
    "# Derived Parameters\n",
    "model_name = cell_type+'_set'+'{}'.format(set)\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "seq_length = X_train.shape[1]\n",
    "embed_size = X_train.shape[2]\n",
    "\n",
    "X_val_t = X_val[:batch_size]\n",
    "y_val_t = y_val_adj[:batch_size]\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type=cell_type)\n",
    "\n",
    "rnn_net = RNN(num_classes, batch_size, seq_length, embed_size, cell_type=cell_type,\n",
    "                 rnn_size=rnn_size, learning_rate=lr, train_keep_prob=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, step 5 loss: 2.3478  validation accuracy: 0.21875  0.3637 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 5 7 5 5 5 8 5 5 5 5 5 5 7 5 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 1, step 10 loss: 2.1765  validation accuracy: 0.15625  0.4166 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 1, step 15 loss: 2.3023  validation accuracy: 0.21875  0.4170 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 5 8 5 5 5 8 5 5 5 5 5 5 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, step 5 loss: 1.9614  validation accuracy: 0.3125  0.4130 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 5 5 8 5 5 5 8 7 5 5 7 5 5 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 2, step 10 loss: 2.0224  validation accuracy: 0.1875  0.4217 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 7 7 7 7 7 7 8 7 7 7 7 7 7 7 7 7 8 7\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 2, step 15 loss: 1.9637  validation accuracy: 0.1875  0.4211 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 7 7 7 7 7 7 8 7 7 7 7 7 7 7 7 7 8 7\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, step 5 loss: 2.0417  validation accuracy: 0.1875  0.4143 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 7 7 7 7 7 7 8 7 7 7 7 7 7 7 7 7 8 7\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 3, step 10 loss: 2.2107  validation accuracy: 0.21875  0.4068 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 6 6 7 6 6 6 8 6 6 6 6 6 6 7 6 6 8 6\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 3, step 15 loss: 1.9679  validation accuracy: 0.28125  0.4157 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 6 6 6 8 6 6 6 8 6 6 6 6 6 6 8 8 8 8 6\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, step 5 loss: 1.6696  validation accuracy: 0.28125  0.4040 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 5 5 5 8 5 5 5 8 8 5 5 5 5 5 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 4, step 10 loss: 1.6690  validation accuracy: 0.28125  0.4077 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 5 5 8 5 5 5 8 5 5 5 5 5 5 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 4, step 15 loss: 2.5591  validation accuracy: 0.15625  0.4150 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, step 5 loss: 2.3815  validation accuracy: 0.21875  0.4194 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 7 7 7 8 7 7 7 8 7 7 7 7 7 7 8 7 8 8 7\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 5, step 10 loss: 1.6441  validation accuracy: 0.3125  0.4094 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   4 4 4 4 8 4 4 4 8 4 4 4 4 4 4 8 5 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 5, step 15 loss: 1.7811  validation accuracy: 0.40625  0.4323 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 4 4 8 4 4 4 8 7 4 4 6 4 4 8 8 8 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, step 5 loss: 1.6492  validation accuracy: 0.40625  0.4031 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 4 7 4 8 4 7 4 8 8 4 4 8 4 7 8 8 8 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 6, step 10 loss: 1.7663  validation accuracy: 0.53125  0.4070 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 4 6 4 8 4 6 4 8 8 4 4 7 4 6 8 8 8 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 6, step 15 loss: 1.5456  validation accuracy: 0.5  0.4103 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 7 4 6 4 7 7 4 4 6 4 6 7 7 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, step 5 loss: 1.4171  validation accuracy: 0.46875  0.4009 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 7 4 6 4 7 7 4 4 6 4 6 7 7 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 7, step 10 loss: 1.4358  validation accuracy: 0.46875  0.4079 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 7 4 7 4 6 4 7 7 4 4 7 4 6 7 7 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 7, step 15 loss: 1.3957  validation accuracy: 0.375  0.4163 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 7 4 8 4 6 4 8 7 5 5 7 4 7 7 7 7 8 6\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, step 5 loss: 1.6149  validation accuracy: 0.5  0.4179 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 4 4 7 4 6 8 7 8 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 8, step 10 loss: 1.2555  validation accuracy: 0.5  0.4147 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 4 4 7 4 6 8 7 8 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 8, step 15 loss: 1.1874  validation accuracy: 0.46875  0.3992 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 8 4 6 5 8 7 5 5 7 5 6 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, step 5 loss: 1.4394  validation accuracy: 0.5  0.4057 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 8 4 6 5 8 7 5 4 7 4 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 9, step 10 loss: 1.3113  validation accuracy: 0.53125  0.4086 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 4 8 7 5 5 7 5 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 9, step 15 loss: 1.5536  validation accuracy: 0.5  0.3995 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 6 5 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, step 5 loss: 1.3427  validation accuracy: 0.5  0.4088 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 6 5 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 10, step 10 loss: 1.4903  validation accuracy: 0.5  0.4101 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 8 4 6 5 8 7 5 5 7 4 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 10, step 15 loss: 1.3013  validation accuracy: 0.5  0.3903 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 5 8 4 6 4 8 7 5 4 7 4 6 8 7 8 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, step 5 loss: 1.3750  validation accuracy: 0.46875  0.4194 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 7 4 8 4 6 4 8 7 5 4 7 4 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 11, step 10 loss: 1.1708  validation accuracy: 0.5  0.4192 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 8 4 6 4 8 7 5 4 7 4 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 11, step 15 loss: 1.2833  validation accuracy: 0.5  0.4146 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 5 5 7 4 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, step 5 loss: 1.2612  validation accuracy: 0.5  0.4049 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 7 5 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 12, step 10 loss: 1.1606  validation accuracy: 0.5  0.3924 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 8 4 6 5 8 7 5 5 7 5 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 12, step 15 loss: 1.2879  validation accuracy: 0.5  0.3855 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 8 4 6 4 8 7 5 5 7 4 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, step 5 loss: 1.3311  validation accuracy: 0.46875  0.3939 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 4 4 6 4 6 8 7 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, step 10 loss: 1.5181  validation accuracy: 0.5  0.4148 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 6 5 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 13, step 15 loss: 1.3879  validation accuracy: 0.53125  0.3989 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 5 4 7 4 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, step 5 loss: 1.3106  validation accuracy: 0.375  0.3919 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 7 5 8 4 6 5 8 7 5 5 7 5 7 8 7 8 8 6\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 14, step 10 loss: 1.3413  validation accuracy: 0.46875  0.3932 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 4 4 6 4 6 8 7 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 14, step 15 loss: 1.0459  validation accuracy: 0.46875  0.3943 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 6 5 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, step 5 loss: 1.1348  validation accuracy: 0.5  0.4109 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 8 4 6 5 8 7 5 5 6 4 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 15, step 10 loss: 1.1327  validation accuracy: 0.46875  0.4054 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 6 5 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 15, step 15 loss: 1.3143  validation accuracy: 0.46875  0.4096 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 5 5 7 4 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, step 5 loss: 1.4302  validation accuracy: 0.5  0.3778 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 7 5 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 16, step 10 loss: 1.1719  validation accuracy: 0.4375  0.4087 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 7 2 6 4 8 7 4 4 6 4 6 7 7 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 16, step 15 loss: 1.4051  validation accuracy: 0.46875  0.4097 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 7 5 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, step 5 loss: 1.1723  validation accuracy: 0.5625  0.4078 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 4 4 6 4 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 17, step 10 loss: 1.2089  validation accuracy: 0.5  0.4166 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 4 4 7 4 6 8 7 8 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 17, step 15 loss: 1.2735  validation accuracy: 0.375  0.4109 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 6 6 5 8 4 6 5 8 7 6 5 7 6 6 8 7 8 8 6\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, step 5 loss: 1.2831  validation accuracy: 0.4375  0.4066 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 7 2 6 5 8 7 5 5 6 5 6 7 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 18, step 10 loss: 1.2258  validation accuracy: 0.46875  0.4169 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 7 4 6 5 8 7 5 5 7 5 6 7 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 18, step 15 loss: 1.6695  validation accuracy: 0.5  0.4006 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 7 5 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, step 5 loss: 1.2935  validation accuracy: 0.53125  0.3959 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 5 4 7 4 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 19, step 10 loss: 1.2830  validation accuracy: 0.5  0.4074 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 6 5 7 5 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 19, step 15 loss: 1.1792  validation accuracy: 0.53125  0.4106 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 5 4 6 4 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, step 5 loss: 1.3455  validation accuracy: 0.5  0.4112 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 7 4 6 4 8 7 5 5 6 4 6 7 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 20, step 10 loss: 1.5525  validation accuracy: 0.46875  0.4207 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 7 4 6 5 8 7 6 6 7 5 6 7 7 7 8 6\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 20, step 15 loss: 1.2499  validation accuracy: 0.46875  0.4205 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 5 5 6 4 6 7 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "Total training time: 152.535\n",
      "Best validation accuracy over the training period was: 0.5625%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = rnn_net.train(batch_gen, X_val_t, y_val_t,\\\n",
    "                                              n_epochs, n_batches, save_every_n=5,\\\n",
    "                                              model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~pmt210/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/miniconda3/envs/EssayGrader_env/lib/python3.6/site-packages/IPython/core/display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pmt210/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_train_loss(train_loss_hist, val_loss_hist, n_batches, model_name)\n",
    "py.iplot(fig, filename='basic-area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your own RNN\n",
    "The LSTM above is able to learn the training set and performance on the validation set is comparable. These preliminary results are promising, but changing hyperparameters can yield even better results. Below is another RNN model definition. Again, many parameters can be modified by the user or left alone with the parameters that yielded our best results.The model will be saved to the 'model/' directory of this project. \n",
    "\n",
    "After many iterations, we found the following mlp parameters yielded the best results on both the training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Defined Parameters\n",
    "\n",
    "batch_size = 32\n",
    "cell_type = 'gru'\n",
    "rnn_size = 256\n",
    "lr = 1e-3\n",
    "n_epochs = 20\n",
    "keep_prob = 1\n",
    "\n",
    "# Derived Parameters\n",
    "model_name = cell_type+'_set'+'{}'.format(set)\n",
    "num_classes = max_score-min_score + 1\n",
    "n_batches = round(X_train.shape[0]/batch_size)\n",
    "seq_length = X_train.shape[1]\n",
    "embed_size = X_train.shape[2]\n",
    "\n",
    "X_val_t = X_val[:batch_size]\n",
    "y_val_t = y_val_adj[:batch_size]\n",
    "batch_gen = get_batches(X_train, y_train_adj, batch_size, net_type=cell_type)\n",
    "\n",
    "rnn_net = RNN(num_classes, batch_size, seq_length, embed_size, cell_type=cell_type,\n",
    "                 rnn_size=rnn_size, learning_rate=lr, train_keep_prob=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network...\n",
      "\n",
      "\n",
      "---------- Training epoch: 1 ----------\n",
      "Epoch 1, step 5 loss: 2.3286  validation accuracy: 0.28125  0.4493 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 5 8 5 8 5 5 5 8 8 5 5 8 5 8 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 1, step 10 loss: 2.2615  validation accuracy: 0.1875  0.4598 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   5 5 5 5 8 5 5 5 8 5 5 5 5 5 5 8 5 6 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 1, step 15 loss: 2.1431  validation accuracy: 0.25  0.4661 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 5 5 5 8 5 5 5 8 6 5 5 6 5 5 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 2 ----------\n",
      "Epoch 2, step 5 loss: 1.6735  validation accuracy: 0.4375  0.4393 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 5 6 5 8 7 5 5 7 5 6 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 2, step 10 loss: 1.5167  validation accuracy: 0.375  0.4581 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 5 6 5 7 5 6 5 7 6 5 5 6 5 6 7 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 2, step 15 loss: 1.3065  validation accuracy: 0.53125  0.4649 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 4 4 7 4 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 3 ----------\n",
      "Epoch 3, step 5 loss: 1.3913  validation accuracy: 0.46875  0.4637 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 4 6 4 8 4 6 4 8 6 5 4 6 4 6 8 6 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 3, step 10 loss: 2.1187  validation accuracy: 0.5  0.4600 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 5 4 7 4 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 3, step 15 loss: 1.4874  validation accuracy: 0.34375  0.4680 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 5 4 7 4 5 4 8 7 4 4 6 4 5 7 7 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 4 ----------\n",
      "Epoch 4, step 5 loss: 1.5792  validation accuracy: 0.4375  0.4611 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 5 6 5 8 7 5 5 7 5 6 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 4, step 10 loss: 1.2378  validation accuracy: 0.46875  0.4649 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 7 4 6 4 8 7 4 4 6 4 6 7 7 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 4, step 15 loss: 1.3434  validation accuracy: 0.40625  0.4650 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 6 6 5 8 4 6 6 8 7 6 6 7 5 6 8 7 7 8 6\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 5 ----------\n",
      "Epoch 5, step 5 loss: 1.2911  validation accuracy: 0.46875  0.4538 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 6 5 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 5, step 10 loss: 1.3780  validation accuracy: 0.46875  0.4564 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 7 5 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 5, step 15 loss: 1.4007  validation accuracy: 0.5  0.4621 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 7 4 6 5 8 7 5 5 7 5 6 7 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 6 ----------\n",
      "Epoch 6, step 5 loss: 1.2416  validation accuracy: 0.53125  0.4484 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 6 5 6 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 6, step 10 loss: 1.4098  validation accuracy: 0.46875  0.4395 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 4 6 4 8 4 6 4 8 6 4 4 6 4 6 8 7 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 6, step 15 loss: 1.3279  validation accuracy: 0.34375  0.4560 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 7 5 8 4 7 5 8 7 5 5 7 5 7 7 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 7 ----------\n",
      "Epoch 7, step 5 loss: 1.5177  validation accuracy: 0.4375  0.4621 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 5 6 5 8 4 5 5 8 7 5 5 7 5 6 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 7, step 10 loss: 1.4882  validation accuracy: 0.4375  0.4616 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 5 4 8 7 4 4 7 4 6 8 7 8 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 7, step 15 loss: 1.3701  validation accuracy: 0.4375  0.4554 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 7 4 6 5 7 7 6 5 7 5 6 7 7 7 9 6\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 8 ----------\n",
      "Epoch 8, step 5 loss: 1.0784  validation accuracy: 0.5625  0.4512 sec/batch\n",
      "Best validation accuracy! - Saving Model\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 4 4 7 4 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 8, step 10 loss: 1.4224  validation accuracy: 0.5  0.4568 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 5 6 4 8 4 6 4 8 8 5 5 6 4 6 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 8, step 15 loss: 1.5195  validation accuracy: 0.46875  0.4632 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 7 4 6 5 7 7 5 5 6 5 6 7 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 9 ----------\n",
      "Epoch 9, step 5 loss: 1.2850  validation accuracy: 0.4375  0.4614 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 6 5 6 7 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 9, step 10 loss: 1.2846  validation accuracy: 0.53125  0.4567 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 7 5 6 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 9, step 15 loss: 1.4541  validation accuracy: 0.53125  0.4601 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 5 4 7 4 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 10 ----------\n",
      "Epoch 10, step 5 loss: 1.4411  validation accuracy: 0.53125  0.4648 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 7 5 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 10, step 10 loss: 1.3225  validation accuracy: 0.5  0.4687 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 8 4 6 5 8 7 5 5 6 4 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 10, step 15 loss: 1.1958  validation accuracy: 0.40625  0.4569 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 7 4 5 4 8 7 4 4 6 4 6 7 7 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 11 ----------\n",
      "Epoch 11, step 5 loss: 1.2205  validation accuracy: 0.53125  0.4551 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 8 4 6 5 8 7 5 5 7 4 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 11, step 10 loss: 1.1164  validation accuracy: 0.53125  0.4614 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 9 7 4 4 7 4 6 8 7 7 9 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 11, step 15 loss: 1.1603  validation accuracy: 0.46875  0.4595 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 8 4 6 5 8 7 5 5 6 5 6 8 7 8 9 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 12 ----------\n",
      "Epoch 12, step 5 loss: 1.1908  validation accuracy: 0.5  0.4634 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 6 5 5 6 5 6 8 7 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 12, step 10 loss: 1.1195  validation accuracy: 0.5  0.4623 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 7 4 6 4 8 7 5 4 6 4 6 7 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 12, step 15 loss: 1.3485  validation accuracy: 0.40625  0.4654 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 7 5 8 4 7 5 9 7 5 5 7 5 7 8 7 8 9 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 13 ----------\n",
      "Epoch 13, step 5 loss: 1.2820  validation accuracy: 0.46875  0.4595 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 7 4 6 5 9 7 5 5 6 4 6 9 7 7 9 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, step 10 loss: 1.4762  validation accuracy: 0.46875  0.4502 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   6 5 6 4 8 4 6 5 8 6 5 5 6 4 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 13, step 15 loss: 1.1396  validation accuracy: 0.375  0.4629 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 5 7 5 8 4 7 5 8 8 6 5 8 5 7 8 8 8 8 6\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 14 ----------\n",
      "Epoch 14, step 5 loss: 1.2130  validation accuracy: 0.4375  0.4615 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 5 4 7 4 5 4 9 7 4 4 7 4 5 7 7 7 9 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 14, step 10 loss: 1.3048  validation accuracy: 0.46875  0.4618 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 9 7 5 5 7 5 6 9 8 8 9 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 14, step 15 loss: 1.2880  validation accuracy: 0.5  0.4631 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 6 4 8 4 6 4 8 7 5 4 7 4 6 8 8 8 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 15 ----------\n",
      "Epoch 15, step 5 loss: 1.2685  validation accuracy: 0.5625  0.4631 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 7 4 6 5 8 7 5 5 7 5 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 15, step 10 loss: 1.2159  validation accuracy: 0.46875  0.4664 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 9 7 5 5 7 5 6 9 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 15, step 15 loss: 1.0520  validation accuracy: 0.53125  0.4568 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 8 4 6 5 9 7 5 5 7 4 6 9 8 8 9 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 16 ----------\n",
      "Epoch 16, step 5 loss: 1.1742  validation accuracy: 0.5625  0.4552 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 7 4 6 5 8 7 5 5 7 4 6 8 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 16, step 10 loss: 1.2364  validation accuracy: 0.53125  0.4549 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 8 7 5 5 6 5 6 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 16, step 15 loss: 1.3410  validation accuracy: 0.375  0.4513 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 4 5 4 8 4 5 4 8 7 4 4 6 4 5 8 8 8 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 17 ----------\n",
      "Epoch 17, step 5 loss: 1.2334  validation accuracy: 0.40625  0.4601 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 7 5 7 4 7 5 9 7 5 5 7 5 7 9 9 8 9 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 17, step 10 loss: 1.2003  validation accuracy: 0.4375  0.4540 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 7 4 6 4 9 7 5 5 7 4 6 9 7 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 17, step 15 loss: 1.4080  validation accuracy: 0.53125  0.4354 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 7 4 6 5 9 7 5 5 7 5 6 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 18 ----------\n",
      "Epoch 18, step 5 loss: 1.2415  validation accuracy: 0.53125  0.4602 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 8 4 6 5 9 7 5 5 7 5 6 8 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 18, step 10 loss: 0.9236  validation accuracy: 0.46875  0.4453 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 7 4 6 5 9 7 5 5 7 4 6 9 7 7 9 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 18, step 15 loss: 1.0413  validation accuracy: 0.4375  0.4559 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 7 4 7 4 7 5 9 7 5 5 7 4 7 9 8 8 9 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 19 ----------\n",
      "Epoch 19, step 5 loss: 1.0316  validation accuracy: 0.46875  0.4589 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 8 4 6 4 9 6 5 4 6 4 6 9 8 8 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 19, step 10 loss: 1.3426  validation accuracy: 0.53125  0.4587 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 7 4 6 5 9 7 5 5 7 5 6 9 8 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 19, step 15 loss: 1.1208  validation accuracy: 0.46875  0.4539 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 7 4 5 5 9 7 5 5 7 5 6 7 7 7 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "\n",
      "---------- Training epoch: 20 ----------\n",
      "Epoch 20, step 5 loss: 1.2628  validation accuracy: 0.5  0.4562 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   8 5 6 5 8 4 6 5 9 7 5 5 7 5 6 9 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 20, step 10 loss: 0.9509  validation accuracy: 0.5625  0.4570 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 5 7 4 6 5 9 7 5 5 7 5 6 9 8 8 8 5\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "Epoch 20, step 15 loss: 1.1342  validation accuracy: 0.46875  0.4498 sec/batch\n",
      "Sample Grade Predictions: \n",
      "Preds:   7 5 6 4 7 4 6 4 9 7 5 5 7 4 6 7 7 7 8 4\n",
      "Actual:  7 5 6 5 7 4 6 4 10 9 4 4 7 4 6 8 8 8 10 5\n",
      "\n",
      "Total training time: 188.379\n",
      "Best validation accuracy over the training period was: 0.5625%\n"
     ]
    }
   ],
   "source": [
    "print('Training Network...')\n",
    "train_loss_hist, val_loss_hist = rnn_net.train(batch_gen, X_val_t, y_val_t,\\\n",
    "                                              n_epochs, n_batches, save_every_n=2,\\\n",
    "                                              model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~pmt210/0 or inside your plot.ly account where it is named 'basic-area'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pmt210/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plot_train_loss(train_loss_hist, val_loss_hist, n_batches, model_name)\n",
    "py.iplot(fig, filename='basic-area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the QWK of the trained model\n",
    "Now we can use essays from the test dataset to obtain a quadratic weighted\n",
    "kappa (QWK) score for the model. This metric is used to quantify how well\n",
    "the model predicted the essay scores relative to random guessing. A value\n",
    "of 0 indicates that the predictions were no better than random guessing,\n",
    "while a value of 1 indicates perfect matching between predictions and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 298 testing essays\n",
      "Testing labels shifted from a scale of (4,12) to (2,10)\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/test_df.pkl'\n",
    "test_df = pd.read_pickle(data_path)\n",
    "df = test_df.loc[test_df['essay_set'] == set]\n",
    "X_test = np.array(df['essays_embed'])\n",
    "y_test = np.array(df['domain1_score'])\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "\n",
    "print('There are {} testing essays'.format(X_test.shape[0]))\n",
    "      \n",
    "if min_score != 0:\n",
    "    y_test_adj = scores_to_preds(y_test, min_score)\n",
    "    print('Testing labels shifted from a scale of ({},{}) to ({},{})'\\\n",
    "          .format(min(y_test),max(y_test), min(y_test_adj), max(y_test_adj)))\n",
    "else:\n",
    "    print('No score adjustment necessary')\n",
    "    y_test_adj = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/gru_set1\n",
      "Running network predictions\n"
     ]
    }
   ],
   "source": [
    "batch_size = X_test.shape[0]\n",
    "seq_length = X_test.shape[1]\n",
    "embed_size = X_test.shape[2]\n",
    "\n",
    "pred_net = RNN(num_classes, batch_size, seq_length, embed_size, cell_type=cell_type,\n",
    "                 rnn_size=rnn_size, learning_rate=lr, train_keep_prob=1)\n",
    "preds = pred_net.predict('./model/'+model_name, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quadratic weighted kappa score for set 1 using gru_set1 is : 0.6883838173986511\n"
     ]
    }
   ],
   "source": [
    "k = quadratic_weighted_kappa(preds[0], y_test_adj, num_classes)\n",
    "\n",
    "print('The quadratic weighted kappa score for set {} using {} is : {}'\\\n",
    "     .format(set, model_name, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets=['set1','set3','set4','set5','set6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/miniconda3/envs/EssayGrader_env/lib/python3.6/site-packages/IPython/core/display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pmt210/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First here is the training time for each set for each model\n",
    "MLP_training_time = [170.3, 25.5, 11.7, 66.4, 33.1]\n",
    "LSTM_training_time = [157.0, 35.0, 30.0, 39.1, 52.3]\n",
    "GRU_training_time = [177.3, 31.4, 33.1, 42.1, 55.4]\n",
    "\n",
    "trace1 = go.Bar(x=sets,y=MLP_training_time,name='MLP')\n",
    "trace2 = go.Bar(x=sets,y=LSTM_training_time,name='LSTM')\n",
    "trace3 = go.Bar(x=sets,y=GRU_training_time,name='GRU')\n",
    "\n",
    "data = [trace1, trace2, trace3]\n",
    "\n",
    "layout = go.Layout(barmode='group',\n",
    "              title='Training Times for each Network and Essay Set',\n",
    "              xaxis=dict(\n",
    "                  title='Essay Set'),\n",
    "              yaxis=dict(\n",
    "                  title='Training Time (s)'),\n",
    "              showlegend=True)\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pmt210/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then, here is the kappa value for each set for each model\n",
    "MLP_kappa = [0.725, 0.546, 0.600, 0.626, 0.512]\n",
    "LSTM_kappa = [0.69, 0.579, 0.551, 0.658, 0.688]\n",
    "GRU_kappa = [0.69, 0.506, 0.689, 0.664, 0.736]\n",
    "\n",
    "trace1 = go.Bar(x=sets,y=MLP_kappa,name='MLP')\n",
    "trace2 = go.Bar(x=sets,y=LSTM_kappa,name='LSTM')\n",
    "trace3 = go.Bar(x=sets,y=GRU_kappa,name='GRU')\n",
    "\n",
    "data = [trace1, trace2, trace3]\n",
    "\n",
    "layout = go.Layout(barmode='group')\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
