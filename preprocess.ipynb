{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook is for the purpose of converting the essays in string form to vectorized form. This notebook makes use of the GLoVe word embeddings. More information about these word embeddings can be found here: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "If you'd like to move directly to the Neural Network, you can skip this notebook completely and load the prepared data directly!\n",
    "\n",
    "If you would like to follow along with the preprocessing work, follow the link above and download the glove.6b.zip file to the \"data/\" directory of this project. Then uncompress the zip file to reveal directory named \"glove.6B/\" with 4 txt files inside. These are the four available word embeddings. You are not able to proceed with this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from src.preprocess import get_data, vectorize_essays\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 3,
   "source": [
    "Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training data from tsv file and store in a pandas dataframe\n",
    "data_path = './data/training_set_rel3.tsv'\n",
    "essay_df = get_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the contents of the dataframe to understand what information is provided in the training set\n",
    "More EDA if we have time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of essays is 12976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Essays Vectorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 Essays Vectorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 Essays Vectorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 Essays Vectorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 Essays Vectorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 Essays Vectorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 Essays Vectorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 Essays Vectorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 Essays Vectorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 Essays Vectorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000 Essays Vectorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000 Essays Vectorized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12976 Total Essays Vectorized!\n"
     ]
    }
   ],
   "source": [
    "essays = essay_df['essay']\n",
    "essay_df['essays_embed'] = vectorize_essays(essays, 100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the preprocessed data frame for later use\n",
    "essay_df.to_pickle('./data/essay_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}